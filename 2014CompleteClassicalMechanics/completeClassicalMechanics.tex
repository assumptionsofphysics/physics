\documentclass[aps,pra,10pt,twocolumn,floatfix,nofootinbib]{revtex4-1}

\usepackage{bbm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{amsfonts}
\usepackage{amsthm}

\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}

\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem*{assump1}{Infinite reducibility (or classical) assumption}
\newtheorem*{assump2}{Determinism and Reversibility assumption}
\newtheorem*{assump3}{Kinematic equivalence assumption}

\begin{document}

\title{From physical principles to relativistic classical Hamiltonian and Lagrangian particle mechanics}
\author{Gabriele Carcassi}
\affiliation{University of Michigan, Ann Arbor, MI 48109}
\email{carcassi@umich.edu}
\date{June 16, 2014}

\begin{abstract}
We show that classical mechanics, including Hamiltonian, Lagrangian, non-relativistic Newtonian gravitation and relativistic electromagnetism, can be derived from three fundamental assumptions: infinite reducibility, deterministic and reversible evolution, and kinematic equivalence. The core idea is that deterministic and reversible systems preserve the cardinality of a set of states, which puts considerable constraints on the equations of motion. Many familiar fundamental concepts and constants (such as mass, the speed of light, the Plank constant, the vector potential) are introduced and defined in a novel way, thus providing different insight into them. The derivation strives to use definition and mathematical concepts that would allow a future extension to quantum mechanics.\end{abstract}
\maketitle

\section{Introduction}


Classical mechanics is usually founded on Newton's laws. These, though, are insufficient to derive the Lagrangian and Hamiltonian formalism, and usually other ad-hoc assumptions (e.g. conservative forces) are introduced. Special relativity is based on two principles (invariance of the speed of light and the principle of relativity), which lead to the Minkowskian nature of space-time but not to the equation of motion, which are a consistent reformulation of the non-relativistic ones. What we'll do in this work is re-organize all the known elements and equations in a more consistent and comprehensive way, leading to better insight on why the fundamental concepts and laws are what they are. The derivation will also include classical analogues of strictly quantum concepts to facilitate a future extension to quantum mechanics.



The above outline should help the reader maintain the big picture, as each section will go through the many details and definitions. We'll keep names and notation as consistent as possible to current use, but this may lead to some non sequitur as it will not be immediately clear why the different definition will be at the end equivalent to the standard one. This is still preferable than introducing a whole new set of names one has to become familiar.

While we try to keep a precise language, no mathematical breakthrough should be expected: the goal, after all, is to derive the \emph{known} framework from a set of \emph{simple} definitions in the most \emph{obvious} way possible. No proof is longer than a couple of paragraphs, so the word \emph{theorem} is avoided in favor of \emph{proposition} and \emph{corollary}. The novel, and surprising, result is how so much can be derived from so little.

\section{Outline}

We give here a brief a general conceptual overview, hoping it will help guide the reader through mathematical details.

We'll first mathematically define states and the labels we use to identify them (e.g. position, momentum, temperature, pressure). We introduce the infinite reducibility assumption (or classical assumption): each state is divisible into the states of its sub-systems. It is then sufficient to describe the evolution of infinitesimal subsystem within their state space (corresponding to point particles in phase space).

We introduce the deterministic and reversible evolution assumption: to each state corresponds one and only one future (or past) state. The cardinality of a set of states is therefore conserved under evolution. This allows us to define a metric $\omega$ on phase space, and the conservation of that metric leads to the Hamiltonian framework. That is: we can derive the Hamiltonian framework on its own merit and show that it is equivalent to deterministic and reversible motion.

We introduce the assumption of kinematic equivalence: studying trajectories is equivalent to studying states. We show that there must be link between the space-time metric $g$ and the phase-space metric $\omega$, as both quantities must be conserved by passive coordinate transformations. That link constrains the space-time metric to be locally Minkowskian. A transformation between state variable $(q, p)$ and kinematic variables $(x, \dot{x})$.  To be invertible, the relationship between velocity and conjugate momentum has to be monotonic, leading to a concave Hamiltonian which allows a Legendre transformation leading to the Lagrangian. We can constrain the Hamiltonian further, and show that the most general equation of motion under the three condition is the one of a geodesic modified by the force given by a vector potential, such as the one of a relativistic charged particle, and a scalar potential, such as the one of newtonian gravitation.


\section{States, Labels and Maps}

The first two sections are dedicated to properly define states. In particular, we will need to introduce more precise terminology to be able to make two crucial distinctions. The first is between the state of the whole system and one of its parts.\footnote{Whole system vs infinitesimal component is also source of confusion when comparing classical and quantum states. Quantum states are always whole systems and are always distributions as there is no state uniquely attributed to its infinitesimal components.}
\begin{center}
    \begin{tabular}{ | p{2.5cm} | p{5.5cm} | }
    \hline
    Configuration state & The state of the whole system being described. \\ \hline
    Particle state (or simply state) & The state of an infinitesimal part (i.e. particle) of the system. \\ \hline
    \end{tabular}
\end{center}
The second is, when referring to a physical quantity, between the space of all possible values, a particular value or a set of possible values.
\begin{center}
    \begin{tabular}{ | p{2.5cm} | p{5.5cm} | }
    \hline
    State variable & A quantity that must be specified to identify a state (e.g. position). \\ \hline
    Label & A particular value for a state variable (e.g. position = $5m$). \\ \hline
    Label set & A set of possible values for a state variable (e.g. position = $[4.5m, 5.5m]$). \\
    \hline
    \end{tabular}
\end{center}
When talking about infinitesimal components and continuous state variables, we must always remember that they are the result of a limit. Therefore we will start with discrete definitions and do the limit, and see how some properties will extend from discrete case to continuous. These are practically the only new terms introduced by this work, but they are fundamental as most of the later derivation will be based on \emph{counting the labels} (i.e. counting the possible values of a physical quantity) and making sure that such number is conserved (i.e. the number of cases is the same).

This section will mathematically define the above concepts, limited to discrete state variables, and derive some basic properties that hold after applying bijective maps.

\begin{defn}\label{statedef}
Suppose we have a physical system to study. We define the set $\mathbbm{C}$ of all physically distinguishable configurations for that system. Each element $\mathbbm{c}$ we call \emph{configuration state}.
\end{defn}

\begin{assump1}\label{classical}
The system is infinitely reducible: it can be thought as composed by two or more similar but smaller systems, each in its own configuration state, which also can be thought as composed by two or more, ad infinitum. We call \emph{particle} such an infinitesimal part.
\end{assump1}

\begin{defn}\label{classicalPhaseSpace}
Let $\mathbbm{S}$ be the set of all possible configuration states for a particle. We call this set \emph{phase space}. We call each $\mathbbm{s} \in \mathbbm{S}$ an \emph{particle state}, or simply \emph{state}.
\end{defn}

\begin{cor}\label{classicalDistribution}
Each classical configuration state $\mathbbm{c} \in \mathbbm{C}$ is a distribution over particle states: $\mathbbm{c}=\sum\limits_{\mathbbm{s} \in \mathbbm{S}} D(\mathbbm{s}) \mathbbm{s}$, where $D:\mathbbm{S}\rightarrow\mathbb{R}$ measures how much of the system can be found in each $\mathbbm{s}$. The distribution can be visualized as a histogram over the states in phase space.
\end{cor}

Under the classical assumption, we can then limit ourselves to study the particles of the system, their states and their properties without loss of generality. To help identify states, we introduce the following concepts.

\begin{defn}\label{label}
We call a \emph{label} a set of states $i\subset\mathbbm{S}$; a \emph{set of labels} a collection of disjoint labels $I | \forall i_1,i_2\in I, i_1\bigcap i_2 = \emptyset$; a \emph{state variable} a set of labels $\mathbbm{I}$ that covers all of phase space: $\bigcup\limits_{i \in \mathbbm{I}}i=\mathbbm{S}$. Therefore a state belongs to one and only one label of a state variable.
\end{defn}

\begin{defn}\label{labelsCombine}
Let $I_1$ and $I_2$ be two sets of labels. We can define the \emph{combined set}, $\langle I_1, I_2 \rangle$, whose labels consist of all the non-empty intersections of one label of $I_1$ and one of $I_2$. If all intersections are non-empty, $I_1$ and $I_2$ are said to be \emph{independent}, and we have $n(\langle I_1, I_2 \rangle)=n(I_1)n(I_2)$ where $n: I \rightarrow \mathbbm{R}$ gives the number of labels of each set.
\end{defn}

We now want to study how states and labels evolve in time, under the following assumption.

\begin{assump2}
The system undergoes deterministic (future state identified by the present state) and reversible (past state identified by the present state) evolution.
\end{assump2}

\begin{prop}\label{detrevMap}
Let $\mathbbm{S}$ be the phase space of a system that undergoes deterministic and reversible evolution. There exists a bijective map $f:\mathbbm{S} \leftrightarrow \mathbbm{S}$ between past and future states.
\end{prop}

\begin{cor}\label{detrevDist}
The evolution of a classical configuration state $\mathbbm{c}=\sum D(\mathbbm{s}) \mathbbm{s}$ under a bijective map is given by $\mathbbm{c'}=\sum D'(\mathbbm{s}) \mathbbm{s}=\sum D(f^{-1}(s)) \mathbbm{s}$. The evolution of the fraction of the system in a label $D(i)=\sum\limits_{\mathbbm{S} \in i} D(\mathbbm{s})$ is given by $D'(i)=D(f^{-1}(i))$.
\end{cor}

Mathematically, assuming determinism and reversibility means studying bijective maps. The evolution of a distribution simply moves the elements around: the bars of the histogram move place, but keep the same height.

\begin{cor}\label{labelsCount}
Given a label $i$, the image $f(i)$ is also a label containing the same number of states. Given a set of labels $I$, the image $f(I)$ is also a set of labels containing the same number of labels. Given a state variable $X$, the image $f(X)$ is also a state variable. Given two independent sets of labels $I_1$ and $I_2$, the images $f(I_1)$ and $f(I_2)$ are also independent. Therefore $n(f(\langle I_1, I_2 \rangle))=n(f(I_1))n(f(I_2))=n(I_1)n(I_2)=n(\langle I_1, I_2 \rangle)$
\end{cor}

Bijective maps preserve the number of labels as they provide one-to-one association between future and past. And they do so for each independent set of labels. These simple results using discrete labels, properly generalized to the continuous case, will give us Hamiltonian flow.

\section{Continuous labels}

The above definitions readily apply for labels identified by integers.\footnote{For each label $i$ there is one and only one integer $z$.} Let $z \in \mathbbm{Z}$, we have $\mathbbm{c}=\sum\limits_{z \in \mathbbm{Z}} D(z) \mathbbm{s}(z)$ and the deterministic map becomes $f:\mathbbm{Z} \leftrightarrow \mathbbm{Z}$. For the continuous case, one may simply expect to replace $z \in \mathbbm{Z}$ with $r \in \mathbbm{R}$, but this does not work. In the continuous limit, we would have $\mathbbm{c}=\int\limits_{r \in \mathbbm{R}} \rho(r) dr \mathbbm{s}(r)$, where $\rho(r) = D(r) / dr$. The continuous distribution $\rho$ is a density, defined over interval $dr$. That is: it's really $\rho(r, dr(r))$, function of both the center and the width of the interval. A bijective map on just $r$ is not sufficient, $dr$ must be mapped as well. On one side we claim the state fully identified by $r$, on the other $dr$ (an different label) is required for the density and the bijective map. We can't have it both ways.
 
In the continuous case, then, the appropriate label corresponds to a cell over $\mathbbm{R}$, not a point. This also makes physical sense, as we never deal with points per se, but widths that can be made arbitrarily small. An cell corresponds to $\mathbbm{R}^2$: the center and the width.\footnote{In other words: the particles of the system are not point-like, but infinitesimal cell-like. Not only this leads to a more direct understanding of phase-space, it is also more consistent with general relativity (the mass is spread across a small region, not forming a singularity) and quantum mechanics (position is really the central value of a small distribution).} With this in mind, we have the following definitions.

\begin{defn}\label{sdof}
A \emph{degree of freedom} is a state variable identified by an infinitesimal cell of a manifold $\mathbbm{Q}$.\footnote{For each label $i$ there is one and only infinitesimal cell.}
\end{defn}

\begin{defn}\label{sdof}
We define the \emph{generalized coordinate} $q$ as the center of each cell. We define the \emph{cell number}\footnote{This represents the classical analogue of the wave number.} $k$ such that $k \, dq$ represents the width of each cell.
\end{defn}

\begin{cor}\label{continuousLabels}
Each degree of freedom is identified by the pair of labels $\langle q,k \rangle \in \mathbf{T}^*\mathbbm{Q}$. $k\,dq$ is invariant under coordinate changes, $dq\wedge dk$ is invariant and $k$ is contravariant.
\end{cor}

Let's start with the discrete case. Let $Q$ be a finite region of $\mathbbm{Q}$. Divide the region in $N$ equal intervals of center $q$ and length $\Delta q$.\footnote{The definition could be mathematically more general. We use equally spaced intervals as it makes the derivation less cumbersome.} Let $K$ be a finite region of $\mathbbm{R}$. Divide the region in $M$ equal intervals of center $k$ and length $\Delta k$. Let $I$ be the label set identified by the cells in $Q$ with center $q(i)$ and width $k(i) \Delta q$. The configuration state will be given by $\mathbbm{c}=\sum\limits_{i \in \mathbbm{I}} \rho(q(i), k(i)) \Delta q \Delta k \mathbbm{s}(q(i), k(i))$, where $\rho(q(i), k(i)) = D(q(i), k(i)) / (\Delta q \Delta k)$.

As we increase $N$ and $M$, the cardinality of the label set $I$ increases, $\Delta q$ and $\Delta k$ decrease and so does the width of the cells. Our definitions, though, do not change: for each $\langle q,k \rangle$ we have one and only one state. In the limit, we will cover every possible center $q$ and evert possible cell number $k$. Our configuration state becomes $\mathbbm{c}=\int\limits_{q \in Q \; k\in K} \rho(q, k) dq \wedge dk \mathbbm{s}(q(i), k(i))$. We can repeat the process increasing or changing the region covered by $Q$ and $K$, until we cover all of $\mathbbm{Q}$ and $\mathbbm{R}$.

If we apply a coordinate change $q'=q'(q)$, we change the labels but the state must remain the same, defined at the same point with the same width. $k' dq'$ must be then equal to $k dq$; $k'= k dq / dq'$ is contravariant, $dq' \wedge dk'= dq'/dq dq \wedge dk dq/dq' = dq \wedge dk$ is invariant. This means that $\rho$ is also invariant, which makes sense: the density depends only on the state (the cell), and not the coordinate chosen to represent them. As $k$ is contravariant, in the limit $K$ becomes the cotangent space of $Q$. Phase space is the cotangent bundle $\mathbf{T}^*\mathbbm{Q}$.

\begin{prop}\label{continuousLabels}
The cardinality of a label set $I$, subset of a degree of freedom, is given by $n(I)=\int \omega$, where $\omega = \hbar \, dq \wedge dk$ and $\hbar$ is a constant that defines the unit of state cardinality.
\end{prop}

As we deal with continuous labels, a label set is uncountable: given any range $\delta q$ and $\delta k$ there are an infinite number of possible labels $I$. Let $I_0$ be another set, defined on $\delta q_0$ and $\delta k_0$. In the discrete case, we have:

\begin{align*}
\frac{n(I)}{n(I_0)} = \frac{\delta q \delta k / \Delta q \Delta k}{\delta q_0 \delta k_0 / \Delta q \Delta k} = \frac{\delta q \delta k}{\delta q_0 \delta k_0}
\end{align*}

That is: while the cardinality of each set diverges, the ratio between the two remains finite.\footnote{Such treatment is exactly equivalent to what one does in information theory to extend Shannon's entropy to the continuous case.} We can redefine our cardinality as the ratio of our set and our reference set $I_0$. That is $n(I)=\hbar \delta q \delta k$ where $\hbar$ is chosen such that $n(I_0)=\hbar \delta q_0 \delta k_0=1$.\footnote{The choice of angular momentum for $\hbar$ derives from the relationship between $p$ and $dq/dt$, which will be derived later. The scale in classical mechanics is arbitrary: we have no physical reason to choose a reference label set over another. In quantum mechanics, instead, we will have a preference: the set that corresponds to a single quantized system.} In general, the label set is not rectangular in $\langle q,k \rangle$ and we have $n(I)=\int \hbar dq \wedge dk$

\begin{defn}\label{conjugateMomentum}
We define the \emph{conjugate momentum} as $p=\hbar k$.
\end{defn}

As $\hbar dq \wedge dk$ is truly fundamental, it is customary to use $dq \wedge (\hbar dk) = dq \wedge dp$. This way the area formed by generalized coordinate and conjugate momentum corresponds to the cardinality of states defined on such area. 

\begin{cor}\label{continuousConjugateRelationships}
Each degree of freedom is identified by the pair of labels $\langle q,p \rangle \in \mathbf{T}^*\mathbbm{Q}$. $\theta_0 = p dq$ and $\omega = dq \wedge dp$ are invariant, $p$ is contravariant. The configuration state over a degree of freedom is $\mathbbm{c}=\int \rho(q,p) dq \wedge dp \mathbbm{s}_{qp}$, where $\rho(q,p)\equiv D(q,p) / \omega$ is the distribution density for each label.
\end{cor}

This restates all the previous findings in terms of conjugate momentum.

In the language of differential geometry, we recognise phase space as the cotangent bundle $\mathbf{T}^*\mathbbm{Q}$, the function $\rho$, the one-form $\theta_0$ and the two-form $\omega$. They are truly fundamental objects as they are intimately linked to the way states are defined ($\rho$ is the distribution, $\theta_0 / \hbar$ is the cell width) and counted ($\omega$ is the cardinality of the labels) and they don't depend on coordinate choice.

\section{Single degree of freedom}

Now that we have properly defined continuous labels and the cardinality of their sets, we will extend bijective maps for the continuous case. As these must preserve the cardinality of label sets, they are constrained in their form, which coincides with Hamilton's equation. In this section we'll study a single degree of freedom, then extend in the next two section to multiple degrees of freedom and to the time dependent case.

\begin{defn}\label{canonical}
We define \emph{canonical transformation} a bijective map on one (or more) degree of freedoms.
\end{defn}

\begin{prop}\label{continuousMapping}
A canonical transformation must be continuous and preserve $\omega$.
\end{prop}

A bijective map conserves the cardinality of labels, see \ref{labelsCount}, therefore $\omega$ must be conserved. The map must be continuous in q: suppose it isn't, it would split some cells into two parts, a cell would not be mapped to one and only one other cell, the mapping would not be bijective. The reverse mapping must be continuous in q as well, or the inverse would not map to one and only one cell.
\begin{align*}
dq' &= \frac{\partial q'}{\partial q} dq + \frac{\partial q'}{\partial p} dp \\
dq &= \frac{\partial q}{\partial q'} dq' + \frac{\partial q}{\partial p'} dp'
\end{align*}
We can re-express $dp'$ in terms of $dq$ and $dp$, as the conservation of $\omega$ means the map is non-degenerate, find that all partial derivatives are well defined, and therefore the mapping is continuous in p as well.

\begin{cor}\label{sdofInvariant}
Let $v$ and $w$ be two vectors defined on the tangent space of the manifold identified by two conjugate variables. Let
\begin{align*}
\omega_{a, b} = \left[
  \begin{array}{cc}
    0 & 1 \\
    -1 & 0 \\
  \end{array}
\right] \\
\end{align*}
then $v'^{a} \omega_{a, b} w'^{b}=v^{a} \omega_{a, b} w^{b}$ under a canonical transformation, where $a$ and $b$ represent component along coordinates $\xi^{a} \equiv \{q,p\}$.
\end{cor}

Here we are simply expressing $\omega$, $v$ and $w$ with their respective components and underlying the fact that $\omega$ defines the metric conserved under canonical transformations.

\begin{lem}\label{genAntisim}
Let $v$ and $w$ be two vectors. Let $v^{a} \omega_{a, b} w^{b}$ be an antisymmetric product conserved under a continuous transformation parameterized by $t$. We can then define a function $H$ such that given $S^{a} \equiv d_{t}\xi^{a}$ and $S_{b} \equiv S^{a} \omega_{a, b}$, we have $S_{a} = \partial_{a}H$.
\end{lem}

$S^{a}$ is the vector field that represents how the state variables change. Simply applying the vector transformation rules under continuous transformation we have:
\begin{align*}
v^{a} \omega_{a, b} w^{b} &= v'^{a} \omega_{a, c} w'^{b}  \\
&= (v^{a} + \partial_{c} S^{a} dt v^{c}) \omega_{a, b} ( w^{b} + \partial_{d} S^{b} w^{d} dt) \\
&= v^{a} \omega_{a, b} w^{b} + (\partial_{c} S^{a} v^{c} \omega_{a, b} w^{b} \\
 &+ v^{a} \omega_{a, b} \partial_{d} S^{b} w^{d}) dt + O(dt^2)
\end{align*}
\begin{align*}
v^{c} w^{b} \partial_{c} S_{b} - v^{a} w^{d} \partial_{d} S_{a} = 0
\end{align*}
\begin{align*}
\partial_{a} S_{b} - \partial_{b} S_{a} &= curl(S_{a}) = 0 \\
S_{a} &= \partial_{a}H
\end{align*}

\begin{prop}\label{sdofHam}
The time evolution for a single degree of freedom is given by:
\begin{align*}
d_{t}q &= \partial_{p} H \\
d_{t}p &= - \partial_{q} H
\end{align*}
\end{prop}

Simply expand \ref{genAntisim} with the metric defined in \ref{sdofInvariant}. We recognize Hamilton's equations for one degree of freedom\cite{classical_dynamics}.

\section{Multiple degrees of freedom}

\begin{prop}\label{mdofInvariant}
Let $v$ and $w$ be two vectors defined on the tangent space of the manifold identified by two independent degrees of freedom. Let $a$ and $b$ be indexes for the state variables $\xi^a\equiv \{q^i, p_i\}$. Let
\begin{align*}
\omega_{\alpha, \beta} =  \left[
  \begin{array}{cc}
    0 & 1 \\
    -1 & 0 \\
  \end{array}
\right] \otimes \left[
  \begin{array}{cc}
    1 & 0 \\
    0 & 1 \\
  \end{array}
\right] =
\left[
  \begin{array}{cccc}
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1 \\
    -1 & 0 & 0 & 0 \\
    0 & -1 & 0 & 0 \\
  \end{array}
\right] \\
\end{align*}
then $v'^{a} \omega_{a, b} w'^{b}=v^{a} \omega_{a, b} w^{a}$ under a canonical transformation.
\end{prop}

The independence between degrees of freedoms corresponds to orthogonality in phase space: from \ref{labelsCombine} the product between the number of labels on each d.o.f. (i.e. the area), must be equal to the number of combines labels (i.e. the hyper-volume), which is true only if the d.o.f are orthogonal in phase space. From \ref{labelsCount}, the mapping will preserve the cardinality of labels, the area\footnote{We assume we are using the same unit across d.o.f.} on each d.o.f, and the independence, orthogonality across d.o.f.\footnote{These statements provide a direct physical interpretation for Gromov's non-squeezing theorem\cite{Gromov,deGosson,Stewart}.} This is equivalent to requiring the conservation of the scalar product across independent degrees of freedom, while still requiring conservation of the vector product within. That leads us to the metric defined by \ref{mdofInvariant}.
The metric generalizes \ref{sdofInvariant} to give us the cardinality of labels defined on the area given by two arbitrary directions in phase space. For an infinitesimal region, this corresponds to $dq^1 \wedge dp^1 + dq^2 \wedge dp^2$, the sum of the projections on the independent planes. Moreover, volume in phase space corresponds to the cardinality of the combined labels (i.e. the states), and is therefore conserved: this is Liouville's theorem.

\begin{prop}\label{mdofHam}
The evolution for multiple degrees of freedom is given by:
\begin{align*}
d_{t}q^i &= \partial_{p_i} H \\
d_{t}p_i &= - \partial_{q^i} H
\end{align*}
\end{prop}

Expand \ref{genAntisim} with the metric defined in \ref{mdofInvariant}. We recognize Hamilton's equations for multiple degrees of freedom\cite{classical_dynamics}.

\section{Time dependence}

So far we have assumed that neither state labeling nor mapping change in time. If they do, we also need to to use time as a label and therefore introduce an extra degree of freedom.

\begin{defn}\label{tdof}
The \emph{temporal degree of freedom} is a state variable identified by temporal cells. The center of each cell is identified by $t$, the width by $\omega dt$, the conjugate variable $E\equiv\hbar\omega$. We call \emph{extended phase space} the outer product between phase space and the temporal degree of freedom.
\end{defn}

\begin{prop}\label{tdofMonotonic}
Let $s$ be the parameter of a trajectory in the extended phase space of a deterministic and reversible system. The trajectory must be continuous. There must exist a strictly monotonic function $t(s)$.
\end{prop}

The trajectory has to be continuous in both standard and temporal variables because of \ref{continuousMapping}. Since determinism and reversibility are defined in time, the trajectory must traverse all times once and only once: we must have an invertible mapping between $t$ and $s$, which means we must have a strictly monotonic $t(s)$.

\begin{defn}\label{tdofAntistates}
We call \emph{standard states} those connected by a trajectory where $d_{s}t>0$. We call \emph{anti-states} those connected by a trajectory where $d_{s}t<0$.
\end{defn}

Since $t(s)$ is strictly monotonic, $d_{s}t$ along a trajectory cannot change sign, so we have the division between standard and anti-states. Note that since the parametrization is conventional and can be changed to $s'=-s$, what we call standard and anti-states is also conventional. What is physical and not conventional, though, is that standard and anti-states cannot be connected by deterministic and reversible evolution.

\begin{prop}\label{tdofInvariant}
Let $v$ and $w$ be two vectors defined on the tangent space of the manifold identified by the temporal degree of freedom and one standard degree of freedom. Let $a$ and $b$ be indexes for the state variables $\xi^a\equiv\{t, E, q, p\}$. Let
\begin{align*}
\omega_{a, b} =  \left[
  \begin{array}{cc}
    0 & 1 \\
    -1 & 0 \\
  \end{array}
\right] \otimes \left[
  \begin{array}{cc}
    -1 & 0 \\
    0 & 1 \\
  \end{array}
\right]
= \left[
  \begin{array}{cccc}
    0 & 0 & -1 & 0 \\
    0 & 0 & 0 & 1 \\
    1 & 0 & 0 & 0 \\
    0 & -1 & 0 & 0 \\
  \end{array}
\right] \\
\end{align*}
then $v'^{a} \omega_{a, b} w'^{b}=v^{a} \omega_{a, b} w^{b}$ under deterministic and reversible evolution.
\end{prop}

$\langle t, E \rangle$ are not independent from $\langle q, p \rangle$ as they do not define new states. So they are not necessarily orthogonal in the extended phase space. Looking back at \ref{discreteLabelDef}, cells need to be defined on the plane where $\langle q, p \rangle$ (maximally) change: this is not the plane of constant $\langle t, E \rangle$ (they are not orthogonal) where $dq \wedge dp$ is defined, but the plane perpendicular to constant $\langle q, p \rangle$ where $dt \wedge dE$ is defined. On that plane we can properly count states and define our invariant.

We have a right triangle-like relationship between the plane where the invariant is defined and its projections on the planes defined by each d.o.f., similar to the multiple d.o.f.:
\begin{align*}
m.d.o.f \;\;\; &dq^1 \wedge dp_1 + dq^2 \wedge dp_2 = k \\
t.d.o.f \;\;\; &dt \wedge dE + k = dq \wedge dp \\
\end{align*}
But in the previous case, the right angle was between the two independent d.o.f.. In this case, the right angle is between the invariant and the plane of constant $\langle q, p \rangle$ where $dt \wedge dE$ is defined. We rewrite it as $dq \wedge dp - dt \wedge dE = k$. This corresponds to the Minkowski product across d.o.f. and the vector product within. The metric, with a space-like convention, still gives us the cardinality of labels within a degree of freedom.\footnote{Adjusted to avoid double counting.}

\begin{prop}\label{tdofHam}
The evolution for time varying multiple degrees of freedom is given by:
\begin{align*}
d_{s}t &= - \partial_{E} \mathcal{H} \\
d_{s}E &= \partial_{t} \mathcal{H} \\
d_{s}q^i &= \partial_{p_i} \mathcal{H} \\
d_{s}p_i &= - \partial_{q^i} \mathcal{H}
\end{align*}
\end{prop}

Take the metric from \ref{tdofInvariant}, add multiple independent d.o.f as in \ref{mdofInvariant}, use \ref{genAntisim} with the parameter $s$ instead of $t$ and generator $\mathcal{H}$ instead of $H$.

If we set\footnote{We avoided using $p^{n+1}$ as it hides the minus sign from the metric, making it seem that the temporal d.o.f is just another independent d.o.f.} $q^{n+1}=t$ and $p^{n+1}=-e$, we recognise Hamilton equations in the extended phase space\footnote{As in Struckmeier\cite{Struckmeier}, $d_{s}t$ need not be unitary.}\cite{Synge,Lanczos}.

It should not be a surprise that the equations do not mention the speed of light $c$. In fact, nothing says that all $q^i$ represent space or that the laws of motion are invariant in all inertial frames. The only requirement we have is that the areas of each degree of freedom represent the same cardinality for labels.

\begin{prop}\label{tdofConstrain}
The evolution is constrained by $\mathcal{H}=k$.
\end{prop}

Since $\mathcal{H}$ is constant through the evolution, it can serve both as the generating function and as the evolution constraint. By convention, we can set $\mathcal{H}=0$ without loss of generality as changing $\mathcal{H}$ by a constant does not change the equation of motion. This reduces extended phase space to $\mathbb{R}^{2*N + 1}$, the state variables plus time.

\section{Kinematics}
So far we talked about states without reference to what they physically represent.

\begin{assump3}\label{kinematicAssumption}
The study of the trajectory (kinematic) of a body is equivalent to study its state (dynamic) under deterministic and reversible evolution.
\end{assump3}

\begin{cor}\label{}
Given all possible space-time trajectory $x^\alpha(s)$ and all possible phase space trajectory $\xi^a(s)$, there exist a bijective function $f: x^\alpha(s) \leftrightarrow \xi^a(s)$ that links each space-time trajectory with one and only one phase space trajectory.
\end{cor}

If studying the motion and state evolution are equivalent, then we must be able to go back and forth between the two pictures. Without losing generality, we can chose $x^\alpha=f(q^i,t)$ to be a function of only $q^i$ and $t$.

\begin{prop}\label{locallyMinkowski}
Space-time is locally Minkowskian Rimmanian manifold. That is, there exists a metric $g_ij$ that at any point can be expressed, with a suitable choice of coordinate, as $dx^\alpha g_{\alpha \beta}|_P dx^\beta=dx^\alpha\eta_{\alpha \beta}dx^\beta=(dx^i)^2 - (dx^0)^2=(dx^i)^2 - c^2dt^2$, where $c=n(dq)/n(dt)$ is the ration between the density of states in space and time.
\end{prop}

As states are defined on intervals, a metric $g$ must be defined on $Q$. Such a metric must be consistent with $\omega$, as both must be invariant under coordinate transformations. The idea is that each $(dx^\alpha)^2$ can be made to both represent a length square in space-time and an area in phase space, linking the two metrics. For each spatial d.o.f. fix $dp_i=\lambda dq^i$, we have $dq^i \wedge dp_i = \lambda (dx^i)^2$ where $\lambda$ converts from units of length squared to cardinality of labels. For the temporal d.o.f fix $dE = \lambda c^2 dt$, we have $dt \wedge dE = \lambda c^2 dt^2$. That is: the area in time squared is converted to an area in length squared that have the same density of states (as per definition of $c$) and then to cardinality of labels. The phase space invariant is $\omega = \lambda [(dq^i)^2 - c^2 dt^2]$.

Assume the choice of coordinates $x^\alpha$ locally diagonalizes $g(x^\alpha)$, each diagonal element being either $\pm 1$ (such coordinate system always exists). Set $x^i=q^i$ and $x^0=ct$. We have $\omega = \lambda ((dx^i)^2 - (dx^0)^2)$ and $dx^\alpha g_{\alpha \beta} dx^\beta=dx^\alpha g_{\alpha \alpha}dx^\alpha$. Both are invariant under coordinate transformation for any $dx^\alpha$. This can only be if $g_{ii}(x^\alpha)=1$ and $g_{00}(x^\alpha)=-1$.

It is fitting that deterministic and reversible evolution requires space-time to be locally Minkowskian, as this clearly defines past and future events. To make us understand better the role of $c$, as we defined it, we prove the following.

\begin{prop}\label{locallyMinkowski}
The speed of a body cannot exceed $c$ under the kinematic equivalence assumption.
\end{prop}

Consider a movement $ds$ along any trajectory. This will go through $n(dt)$ labels in time and $n(dq)$ labels in space. As the motion is continuous, the number of labels in space cannot exceed the number of labels in time, we can't skip them, therefore $n(dq)\leq c n(dt)$. So we have:
\begin{align*}
\frac{n(dq)}{n(dt)}= \frac{dq}{dt} \leq c \\
\end{align*}

\begin{prop}\label{initialConditions}
Let $u^\alpha = d_s x^\alpha$ be the four-velocity, where the parametrization $s$ is chosen, by convention, to be proper time. The position $x^\alpha$ and velocity $u^\alpha$ are necessary and sufficient initial conditions to determine the state of the system and its whole trajectory.
\end{prop}

The equation of motion \ref{tdofHam} can be at most second order in $q^i$, they can at most be second order in $x^\alpha=\{ct, q^i\}$ so only position and velocity can be candidates for the initial conditions. Fixing time, phase space is $\mathbbm{R}^{2n}$, too big to be covered by position only, but just right to be covered by both.

\begin{prop}\label{kineticMomentum}
Let $x^\alpha=\{ct, q^i\}$ and $p_\alpha=\{-E/c, p_i\}$. Then $p_\alpha= m g_{\alpha \beta}u^\beta + \hat{p}_\alpha(x^\gamma)$, where $m=n(dp_\alpha)/n(d(g_{\alpha \beta}u^\beta))$ is the ration between the density of states in conjugate momentum and in contravariant velocity, and is called \emph{inertial mass}.
\end{prop}

For \ref{kinematicAssumption} and \ref{kineticMomentum}, there must exist $p_\alpha=p_\alpha(x^\beta , u^\gamma)$. We express it in terms of $u_\alpha\equiv g_{\alpha \beta} u^\beta$. We have:
\begin{align*}
\omega &= q^i\wedge p_i - ct \wedge E/c \\
&=x^\alpha \wedge p_\alpha \\
&=dx^\alpha \wedge \frac{\partial p_\alpha}{\partial u_\beta}du_\beta + dx^\alpha \wedge \frac{\partial p_\alpha}{\partial x^\gamma}dx^\gamma \\
&=\frac{\partial p_\alpha}{\partial u_\beta}du_\beta dx^\alpha \\
\end{align*}
Consider the expression $m du_\alpha dx^\alpha$: this gives us the density of labels in position and velocity converted to the conjugate variables. In other world, we should have $\omega=m du_\alpha dx^\alpha$. This means:
\begin{align*}
\frac{\partial p_\alpha}{\partial u_\beta} &= m \delta^\beta_\alpha \\
p_\alpha &= m g_{\alpha \beta}u^\beta + \hat{p}_\alpha(x^\gamma)
\end{align*}
where $\hat{p}$ is an arbitrary function.

To convince ourselves that $m$ is indeed the inertial mass, consider applying a force. We are changing the state through the velocity, meaning changing the conjugate momentum. The higher the mass, the more states we'll have to go through to reach the same velocity. The higher the mass, the more change is required, the more force needs to be applied.

\begin{prop}\label{kineticHamiltonian}
The extended Hamiltonian is $\mathcal{H}=\frac{1}{2m}(p_\alpha-\hat{p}_\alpha(x))g^{\alpha\beta}(p_\beta-\hat{p}_\beta(x))+\hat{\mathcal{H}}(x)$
\end{prop}
We have:
\begin{align*}
\frac{dq^\alpha}{ds} &= u^\alpha \\
&= \frac{1}{m}g^{\alpha\beta}(p_\beta-\hat{p}_\beta) \\
&= \frac{\partial \mathcal{H}}{dp_\alpha} \\
\end{align*}
Integrating we have the expression for the Hamiltonian, where $\hat{\mathcal{H}}$ is an arbitrary function.

\begin{prop}\label{kineticLaw}
Let $\hat{p}_\alpha = q A_\alpha$, $F_{\alpha \beta} \equiv \partial_\alpha A_\beta - \partial_\beta A_\alpha$ and $\hat{H} = 0$, the equations of motion are $m \nabla_s u^\alpha = g^{\alpha\beta} F_{\beta \gamma} q u^\gamma$.
\end{prop}

We first derive the following relationship for later use:
\begin{align*}
\partial_\alpha \delta^\beta_\gamma &= 0 = \partial_\alpha g^{\beta\delta} g_{\delta\gamma} + g^{\beta\delta} \partial_\alpha g_{\delta\gamma}\\
\partial_\alpha g^{\beta\epsilon} &= - g^{\beta\delta} g^{\gamma\epsilon} \partial_\alpha g_{\delta\gamma}
\end{align*}

We expand \ref{tdofHam} using \ref{kineticHamiltonian}:
\begin{align*}
u^\alpha &= \frac{dq^\alpha}{ds} = \frac{\partial \mathcal{H}}{dp_\alpha} \\
&= \frac{1}{m}g^{\alpha\beta}(p_\beta-\hat{p}_\beta) \\
d_s p_\alpha &= - \frac{\partial \mathcal{H}}{\partial q^\alpha} \\
&=\frac{1}{2m}[\partial_\alpha \hat{p}_\beta g^{\beta \gamma} (p_\gamma -\hat{p}_\gamma) \\
 &- (p_\beta -\hat{p}_\beta) \partial_\alpha g^{\beta \gamma} (p_\gamma -\hat{p}_\gamma) \\
 &+ (p_\beta -\hat{p}_\beta) g^{\beta \gamma} \partial_\alpha \hat{p}_\gamma ]- \partial_\alpha \hat{H} \\
&=\frac{1}{2}[\partial_\alpha \hat{p}_\beta u^\beta
- m u^\delta g_{\delta\beta} \partial_\alpha g^{\beta \gamma} u^\epsilon g_{\epsilon\gamma}
+ u^\gamma \partial_\alpha \hat{p}_\gamma ]- \partial_\alpha \hat{H}
\end{align*}

We then calculate the four-force:
\begin{align*}
m d_s u^\alpha &= d_s g^{\alpha\beta}(p_\beta-\hat{p}_\beta) + g^{\alpha\beta} d_s (p_\beta-\hat{p}_\beta) \\
&= \partial_\gamma g^{\alpha\beta} d_s x^\gamma m g_{\beta \delta} u^\delta + g^{\alpha\beta} (d_s p_\beta - \partial_\gamma \hat{p}_\beta d_s x^\gamma) \\
&= \partial_\gamma g^{\alpha\beta} u^\gamma m g_{\beta \delta} u^\delta + g^{\alpha\beta} \frac{1}{2} [\partial_\beta \hat{p}_\gamma u^\gamma
- m u^\epsilon g_{\epsilon\gamma} \partial_\beta g^{\gamma \delta} u^\zeta g_{\zeta\delta} \\
&+ u^\delta \partial_\beta \hat{p}_\delta ]- g^{\alpha\beta} \partial_\beta \hat{H} - g^{\alpha\beta} \partial_\gamma \hat{p}_\beta u^\gamma \\
&= m  g_{\beta \delta} \partial_\gamma g^{\alpha\beta} u^\gamma u^\delta - \frac{1}{2} m g^{\alpha\beta} g_{\zeta\delta} g_{\epsilon\gamma} \partial_\beta g^{\gamma \delta} u^\epsilon u^\zeta  \\
&+ g^{\alpha\beta} \partial_\beta \hat{p}_\gamma u^\gamma - g^{\alpha\beta} \partial_\gamma \hat{p}_\beta u^\gamma
- g^{\alpha\beta} \partial_\beta \hat{H}\\
&= - m  g^{\alpha \beta} \partial_\gamma g_{\beta\delta} u^\gamma u^\delta + \frac{1}{2} m g^{\alpha\beta} \partial_\beta g_{\gamma \delta} u^\gamma u^\delta  \\
&+ g^{\alpha\beta} (\partial_\beta \hat{p}_\gamma - \partial_\gamma \hat{p}_\beta ) u^\gamma
- g^{\alpha\beta} \partial_\beta \hat{H}\\
&= - m \frac{1}{2} g^{\alpha \beta} ( \partial_\gamma g_{\beta\delta} + \partial_\delta g_{\beta\gamma} - \partial_\beta g_{\gamma \delta} ) u^\gamma u^\delta  \\
&+ g^{\alpha\beta} (\partial_\beta \hat{p}_\gamma - \partial_\gamma \hat{p}_\beta ) u^\gamma
- g^{\alpha\beta} \partial_\beta \hat{H}\\
&= - m \Gamma ^\alpha_{\ \gamma \delta} u^\gamma u^\delta + g^{\alpha\beta} (\partial_\beta \hat{p}_\gamma - \partial_\gamma \hat{p}_\beta ) u^\gamma
- g^{\alpha\beta} \partial_\beta \hat{H}
\end{align*}
\begin{align*}
m \nabla_{u} u^\alpha &= m (d_s u^\alpha + \Gamma ^\alpha_{\ \gamma \delta} u^\gamma u^\delta)  \\
&= g^{\alpha\beta} (\partial_\beta \hat{p}_\gamma - \partial_\gamma \hat{p}_\beta ) u^\gamma - g^{\alpha\beta} \partial_\beta \hat{H}\\
&= g^{\alpha\beta} (\nabla_\beta \hat{p}_\gamma - \nabla_\gamma \hat{p}_\beta ) u^\gamma - g^{\alpha\beta} \nabla_\beta \hat{H}
\end{align*}

The equation is manifestly covariant. If $\hat{p}$ and $\hat{H}$ are zero, absence of forces, we recognize the geodesic equation. We substitute $\hat{p}_\alpha = q A_\alpha$ and $\hat{H} = 0$ and have:

\begin{align*}
m \nabla_{u} u^\alpha &= g^{\alpha\beta} (\partial_\beta A_\gamma - \partial_\gamma A_\beta ) q u^\gamma \\
&= g^{\alpha\beta} F_{\beta \gamma} q u^\gamma\\
\end{align*}

This is the relativistic equation for a charged particle.

\section{Lagrangian}

From Hamiltonian conservation to Lagrangian. p monotonic means convex Hamiltonian: can use Legendre transform.

\section{Conclusion}

\begin{thebibliography}{0}

\bibitem{Jaynes} Jaynes, E. T.: ``Information theory and statistical mechanics'', (1963)
\bibitem{Shannon} Shannon, C. E.: ``A mathematical theory of communications'', The Bell System Technical Journal, Vol. 27, pp. 379–423, 623–656, (1948)
\bibitem{classical_dynamics} J. V. Jose', E. J. Saletan: ``Classical Dynamics'', Cambridge University Press, (1998)
\bibitem{Gromov} Gromov, M. L.: ``Pseudo holomorphic curves in symplectic manifolds''. Inventiones Mathematicae 82: 307–347, (1985)
\bibitem{deGosson} de Gosson, M. A.: ``The symplectic camel and the uncertainty principle: the tip of an iceberg?'', Foundation of Physics 39, pp. 194–214, (2009)
\bibitem{Stewart} Stewart, I.: ``The symplectic camel'', Nature 329(6134), 17–18 (1987)
\bibitem{Lanczos} Lanczos, C.: ``The variational principles of mechanics'', University of Toronto Press (1949)
\bibitem{Synge} Synge, J. L.: Encyclopedia of Physics Vol 3/1, Springer (1960)
\bibitem{Struckmeier} Struckmeier, J.: ``Hamiltonian dynamics on the symplectic extended phase space for autonomous and non-autonomous systems'', J. Phys. A: Math. Gen 38, 1257-1278, (2005)

\end{thebibliography}

\end{document}
