\documentclass[aps,pra,10pt,twocolumn,floatfix,nofootinbib]{revtex4-1}

\usepackage{bbm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{amsfonts}
\usepackage{amsthm}

\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}

\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem*{assump1}{Infinite reducibility (or classical) assumption}
\newtheorem*{assump2}{Determinism and Reversibility assumption}
\newtheorem*{assump3}{Kinematic equivalence assumption}

\begin{document}

\title{From physical principles to relativistic classical Hamiltonian and Lagrangian particle mechanics}
\author{Gabriele Carcassi}
\affiliation{University of Michigan, Ann Arbor, MI 48109}
\email{carcassi@umich.edu}
\date{June 16, 2014}

\begin{abstract}
We show that classical mechanics, including Hamiltonian, Lagrangian, non-relativistic Newtonian gravitation and relativistic electromagnetism, can be derived from three fundamental assumptions: infinite reducibility, deterministic and reversible evolution, and kinematic equivalence. The core idea is that deterministic and reversible systems preserve the cardinality of a set of states, which puts considerable constraints on the equations of motion. This perspective links different concepts from different branches of math and physics (cardinality of a set, cotangent bundle for phase space, locally Minkowskian space-time manifold, inertial mass) providing new insights. The derivation strives to use definition and mathematical concepts that would allow a future extension to quantum mechanics.\end{abstract}
\maketitle

\section{Introduction}


Classical mechanics is usually founded on Newton's laws. These, though, are insufficient to derive the Lagrangian and Hamiltonian formalism, and usually other ad-hoc assumptions (e.g. conservative forces) are introduced. Special relativity is based on two principles (invariance of the speed of light and the principle of relativity), which lead to the Minkowskian nature of space-time but not to the equation of motion, which are a consistent reformulation of the non-relativistic ones. What we'll do in this work is re-organize all the known elements and equations in a more consistent and comprehensive way, leading to better insight on why the fundamental concepts and laws are what they are. The derivation will also include classical analogues of strictly quantum concepts to facilitate a future extension to quantum mechanics.

We will use concepts from different disciplines, such as set theory, differential geometry, relativity, Hamiltonian and Lagrangian mechanics, and will find interesting connections between them. We'll keep names and notation as consistent as possible to current use across the different disciplines, but this may lead to some non sequitur as it will not be immediately clear why the different definition will be at the end equivalent to the standard one. This is still preferable than introducing a whole new set of names one has to become familiar.

No mathematical breakthrough should be expected: the goal, after all, is to derive the \emph{known} framework from a set of \emph{simple} definitions in the most \emph{obvious} way possible. No proof is longer than a couple of paragraphs, so the word \emph{theorem} is avoided in favor of \emph{proposition} and \emph{corollary}. The novel, and surprising, result is how so much can be derived from so little.

\section{Outline}

We give here a brief a general conceptual overview, hoping it will help guide the reader through the mathematical details.

We'll first mathematically define states and the labels we use to identify them (e.g. position, momentum, temperature, pressure). We introduce the infinite reducibility assumption (or classical assumption): each state is divisible into the states of its parts. It is then sufficient to describe the evolution of infinitesimal parts (i.e. particles) within their state space (i.e. phase space).

We introduce the deterministic and reversible evolution assumption: to each state corresponds one and only one future (or past) state. The cardinality of a set of states is therefore conserved under evolution. This allows us to define a metric $\omega$ on phase space, and the conservation of that metric leads to the Hamiltonian framework. That is: we can derive the Hamiltonian framework on its own merit and show that it is equivalent to deterministic and reversible motion.

We introduce the assumption of kinematic equivalence: studying trajectories is equivalent to studying states. We show that there must be link between the space-time metric $g$ and the phase-space metric $\omega$, as both quantities must be conserved under passive coordinate transformations. That link constrains the space-time metric to be locally Minkowskian. A transformation between state variables $(q, p)$ and kinematic variables $(x, \dot{x})$ must exist.  To be invertible, the relationship between velocity and conjugate momentum has to be monotonic, leading to a concave Hamiltonian which allows a Legendre transformation leading to the Lagrangian. We can constrain the Hamiltonian further, and show that the most general equation of motion under the three assumptions is the one of a geodesic modified by the force given by a vector potential (such as the one of a relativistic charged particle) and a scalar potential (such as the one of newtonian gravitation).


\section{States, Labels and Maps}

This and the next section are dedicated to properly define states. In particular, we will need to introduce more precise terminology to be able to make two crucial distinctions. The first is between the state of the whole system and one of its parts.\footnote{Whole system vs infinitesimal component is also source of confusion when comparing classical and quantum states. Quantum states are always whole systems and are always distributions as there is no state uniquely attributed to its infinitesimal components.}
\begin{center}
    \begin{tabular}{ | p{2.5cm} | p{5.5cm} | }
    \hline
    Configuration state & The state of the whole system being described. \\ \hline
    Particle state (or simply state) & The state of an infinitesimal part (i.e. particle) of the system. \\ \hline
    \end{tabular}
\end{center}
When talking about particles of a system we must always remember that they are the result of a limit. Therefore we will start with discrete definitions, and see how some properties will extend from discrete case to continuous.

The second distinctions is, when referring to a physical quantity, between the space of all possible values, a particular value or a set of possible values.
\begin{center}
    \begin{tabular}{ | p{2.5cm} | p{5.5cm} | }
    \hline
    State variable & A quantity that must be specified to identify a state (e.g. position). \\ \hline
    Label & A particular value for a state variable (e.g. position = $5m$). \\ \hline
    Label set & A set of possible values for a state variable (e.g. position = $[4.5m, 5.5m]$). \\
    \hline
    \end{tabular}
\end{center}

We will first define discrete labels using set theory and in the next section generalize to the continuous case using differential geometry. These new terms are fundamental as most of the later derivation will be based on \emph{counting the labels} (i.e. counting the possible values of a physical quantity) and making sure that such number is conserved (i.e. the number of cases is the same).

\begin{defn}\label{statedef}
Fix a physical system to study. We define the set $\mathbbm{C}$ of all physically distinguishable configurations for that system. Each element $\mathbbm{c}$ we call \emph{configuration state}.
\end{defn}

\begin{assump1}\label{classical}
The system is infinitely reducible: it can be thought as composed by two or more similar but smaller systems, each in its own configuration state, which also can be thought as composed by two or more, ad infinitum. We call \emph{particle} such an infinitesimal part.
\end{assump1}

\begin{defn}\label{classicalPhaseSpace}
Let $\mathbbm{S}$ be the set of all possible configuration states for a particle. We call this set \emph{phase space}. We call each $\mathbbm{s} \in \mathbbm{S}$ a \emph{particle state}, or simply \emph{state}.
\end{defn}

\begin{cor}\label{classicalDistribution}
Each classical configuration state $\mathbbm{c} \in \mathbbm{C}$ is a distribution over particle states: $\mathbbm{c}=\sum\limits_{\mathbbm{s} \in \mathbbm{S}} D(\mathbbm{s}) \mathbbm{s}$, where $D:\mathbbm{S}\rightarrow\mathbb{R}$ measures how much of the system can be found in each $\mathbbm{s}$. The distribution can be visualized as a histogram over the states in phase space.
\end{cor}

Under the classical assumption, we can then limit ourselves to study the particles of the system, their states and their properties without loss of generality. To help identify states, we introduce the following concepts.

\begin{defn}\label{label}
We call a \emph{label} a set of states $i\subset\mathbbm{S}$; a \emph{set of labels} a collection of disjoint labels $I | \forall i_1,i_2\in I, i_1\bigcap i_2 = \emptyset$; a \emph{state variable} a set of labels $\mathbbm{I}$ that covers all of phase space: $\bigcup\limits_{i \in \mathbbm{I}}i=\mathbbm{S}$. Therefore a state belongs to one and only one label of a state variable.
\end{defn}

\begin{defn}\label{discreteCardinality}
Let $I$ be a finite, countable set of labels. We define the \emph{cardinality} $n: I \rightarrow \mathbbm{N}$ as the number of labels in the set.
\end{defn}

\begin{defn}\label{labelsCombine}
Let $I_1$ and $I_2$ be two sets of labels. We can define the \emph{combined set}, $\langle I_1, I_2 \rangle$, whose labels consist of all the non-empty intersections of one label of $I_1$ and one of $I_2$. If all intersections are non-empty, $I_1$ and $I_2$ are said to be \emph{independent}, and we have $n(\langle I_1, I_2 \rangle)=n(I_1)n(I_2)$.
\end{defn}

We now want to study how states and labels evolve in time, under the following assumption.

\begin{assump2}
The system undergoes deterministic (future state identified by the present state) and reversible (past state identified by the present state) evolution.
\end{assump2}

\begin{prop}\label{detrevMap}
Let $\mathbbm{S}$ be the phase space of a system that undergoes deterministic and reversible evolution. There exists a bijective map $f:\mathbbm{S} \leftrightarrow \mathbbm{S}$ between past and future states.
\end{prop}

\begin{cor}\label{detrevDist}
The evolution of a classical configuration state $\mathbbm{c}=\sum D(\mathbbm{s}) \mathbbm{s}$ under a bijective map is given by $\mathbbm{c'}=\sum D'(\mathbbm{s}) \mathbbm{s}=\sum D(f^{-1}(\mathbbm{s})) \mathbbm{s}$. The evolution of the fraction of the system in a label $D(i)=\sum\limits_{\mathbbm{S} \in i} D(\mathbbm{s})$ is given by $D'(i)=D(f^{-1}(i))$.
\end{cor}

Mathematically, assuming determinism and reversibility means studying bijective maps. The evolution of a distribution simply moves the elements around: the bars of the histogram move place, but keep the same height.

\begin{cor}\label{labelsCount}
Given a label $i$, the image $f(i)$ is also a label containing the same number of states. Given a set of labels $I$, the image $f(I)$ is also a set of labels containing the same number of labels $n(I) = n(f(I))$. Given a state variable $\mathbbm{I}$, the image $f(\mathbbm{I})$ is also a state variable. Given two independent sets of labels $I_1$ and $I_2$, the images $f(I_1)$ and $f(I_2)$ are also independent. Therefore $n(f(\langle I_1, I_2 \rangle))=n(f(I_1))n(f(I_2))=n(I_1)n(I_2)=n(\langle I_1, I_2 \rangle)$
\end{cor}

Bijective maps preserve the number of labels as they provide one-to-one association between future and past. And they do so for each independent set of labels. These simple results using discrete labels, properly generalized to the continuous case, will give us Hamiltonian flow.

\section{Numeric labels}

We now focus on labels that can be identified by numbers, where we have a bijective map between the label and a number in a set. The definitions in the previous section readily apply for labels identified by integers. Let $z \in \mathbbm{Z}$, we have $\mathbbm{c}=\sum\limits_{z \in \mathbbm{Z}} D(z) \mathbbm{s}(z)$ and the deterministic map becomes $f:\mathbbm{Z} \leftrightarrow \mathbbm{Z}$.

For the continuous case, one may simply expect to replace $z \in \mathbbm{Z}$ with $r \in \mathbbm{R}$, but this does not work. In the continuous limit, we would have $\mathbbm{c}=\int\limits_{r \in \mathbbm{R}} \rho(r) dr \mathbbm{s}(r)$, where $\rho(r) = D(r) / dr$. The continuous distribution $\rho$ is a density, defined over interval $dr$. That is: it's really $\rho(r, dr(r))$, function of both the center and the width of the interval. A bijective map on just $r$ is not sufficient, $dr$ must be mapped as well. On one side we claim the state fully identified by $r$, on the other $dr$ (a different label) is required for the density and the bijective map. We can't have it both ways.

In the continuous case, then, the appropriate label corresponds to a cell, not a point. This also makes physical sense, as we never deal with points per se, but widths that can be made arbitrarily small. A cell of $\mathbbm{R}$ corresponds to $\mathbbm{R}^2$: a center and a width.\footnote{In other words: the particles of the system are not point-like, but infinitesimal cell-like. Not only this leads to a more direct understanding of phase-space, it is also more consistent with general relativity (the mass is spread across a small region, not forming a singularity) and quantum mechanics (position is really the central value of a small distribution).} With this in mind, we have the following definitions.

\begin{defn}\label{sdof}
A \emph{degree of freedom} is a state variable identified by an infinitesimal cell of a one dimensional manifold $\mathbbm{Q}$.\footnote{For each label $i$ there is one and only infinitesimal cell.}
\end{defn}

\begin{defn}\label{sdof}
We define the \emph{generalized coordinate} $q$ as the center of each cell. We define the \emph{cell number}\footnote{This represents the classical analogue of the wave number.} $k$ such that $k \, dq$ represents the width of each cell.
\end{defn}

\begin{cor}\label{continuousLabels}
Each degree of freedom is identified by the pair of labels $\langle q,k \rangle \in \mathbf{T}^*\mathbbm{Q}$. Under coordinate changes, $k\,dq$ and $dq\wedge dk$ are invariant and $k$ is contravariant.
\end{cor}

Let's start with the discrete case. Let $Q$ be a finite region of $\mathbbm{Q}$. Divide the region in $N$ equal intervals of center $q$ and length $\Delta q$.\footnote{The definition could be mathematically more general. We use equally spaced intervals as it makes the derivation less cumbersome.} Let $K$ be a finite region of $\mathbbm{R}$. Divide the region in $M$ equal intervals of center $k$ and length $\Delta k$. Let $I$ be the label set identified by the cells in $Q$ with center $q(i)$ and width $k(i) \Delta q$. The configuration state will be given by $\mathbbm{c}=\sum\limits_{i \in I} \rho(q(i), k(i)) \Delta q \Delta k \, \mathbbm{s}(q(i), k(i))$, where $\rho(q(i), k(i)) = D(q(i), k(i)) / (\Delta q \Delta k)$.

As we increase $N$ and $M$, the cardinality of the label set $I$ increases, $\Delta q$ and $\Delta k$ decrease and so does the width of the cells. Our definitions, though, do not change: for each $\langle q,k \rangle$ we have one and only one cell, one state. In the limit, we will cover every possible center $q$ and every possible cell number $k$. Our configuration state becomes $\mathbbm{c}=\int\limits_{q \in Q \; k\in K} \rho(q, k) dq \wedge dk \, \mathbbm{s}(q(i), k(i))$. We can repeat the process increasing or changing the region covered by $Q$ and $K$, until we cover all of $\mathbbm{Q}$ and $\mathbbm{R}$.

If we apply a coordinate change $q'=q'(q)$, we change the labels but the state must remain the same, defined at the same point with the same width. $k' dq'$ must be then equal to $k dq$; $k'= k dq / dq'$ is contravariant, $dq' \wedge dk'= dq'/dq \, dq \wedge dk \, dq/dq' = dq \wedge dk$ is invariant. This means that $\rho$ is also invariant, which makes sense: the density depends only on the state (the cell), and not the coordinate chosen to represent them. As $k$ is contravariant, in the limit $K$ becomes the cotangent space of $Q$. Phase space is the cotangent bundle $\mathbf{T}^*\mathbbm{Q}$.

\begin{prop}\label{relativeCardinality}
Let $I$ be a closed dense set of labels, subset of a degree of freedom. We define \emph{relative cardinality} $n: I \rightarrow \mathbbm{R}$ the ratio between the number of labels in $I$ and the ones of a reference set $I_0$. We find $n(I)=\int \omega$, where $\omega = \hbar \, dq \wedge dk$ and $\hbar$ is the constant that determines the unit (i.e. chosen so $n(I_0)=1$).
\end{prop}

As we deal with continuous labels, a label set is uncountable: given any range $\delta q$ and $\delta k$ there are an infinite number of possible labels $I$. Let $I_0$ be another set, defined on $\delta q_0$ and $\delta k_0$. In the discrete case, we have:

\begin{align*}
\frac{n(I)}{n(I_0)} = \frac{\delta q \delta k / \Delta q \Delta k}{\delta q_0 \delta k_0 / \Delta q \Delta k} = \frac{\delta q \delta k}{\delta q_0 \delta k_0}
\end{align*}

That is: while the cardinality of each set diverges, the ratio between the two remains finite.\footnote{Such treatment is exactly equivalent to what one does in information theory to extend Shannon's entropy to the continuous case. There is a link between label cardinality and informational entropy, whichwe do not explore here for brevity.} For continuous state variables we can define the relative cardinality as the ratio of a label set and our reference set $I_0$. That is $n(I)=\hbar \delta q \delta k$ where $\hbar$ is chosen such that $n(I_0)=\hbar \delta q_0 \delta k_0=1$.\footnote{The choice of angular momentum for $\hbar$ derives from the relationship between $p$ and $dq/dt$, which will be derived later. The value for $\hbar$ in classical mechanics is arbitrary: we have no physical reason to choose a reference label set over another. In quantum mechanics, instead, we will have a preference: the set that corresponds to a single quantized system. We use this arbitrariness to set $\hbar$ to the value to the known constant.} In general, the label set is not rectangular in $\langle q,k \rangle$ and we have $n(I)=\int \hbar dq \wedge dk$

\begin{defn}\label{conjugateMomentum}
We define the \emph{conjugate momentum} as $p=\hbar k$.
\end{defn}

As $\hbar dq \wedge dk$ is truly fundamental, it is customary to group $\hbar$ with $k$: $dq \wedge (\hbar dk) = dq \wedge dp$. This way the area formed by generalized coordinate and conjugate momentum corresponds to the cardinality of states defined on such area.

\begin{cor}\label{continuousConjugateRelationships}
Each degree of freedom is identified by the pair of labels $\langle q,p \rangle \in \mathbf{T}^*\mathbbm{Q}$. $\theta_0 = p dq$ and $\omega = dq \wedge dp$ are invariant, $p$ is contravariant. The configuration state over a degree of freedom is $\mathbbm{c}=\int \rho(q,p) dq \wedge dp \, \mathbbm{s}_{qp}$, where $\rho(q,p)\equiv D(q,p) / \omega$ is the distribution density for each label.
\end{cor}

This restates all the previous findings in terms of conjugate momentum.

In the language of differential geometry, we recognise phase space as the cotangent bundle $\mathbf{T}^*\mathbbm{Q}$, the function $\rho$, the one-form $\theta_0$ and the two-form $\omega$. They are truly fundamental objects as they are intimately linked to the way states are defined ($\rho$ is the distribution, $\theta_0 / \hbar$ is the cell width) and counted ($\omega$ is the cardinality of the labels) and they don't depend on coordinate choice.

\section{Single degree of freedom}

Now that we have properly defined continuous labels and the relative cardinality of their sets, we will extend bijective maps to the continuous case. As these must preserve the cardinality of label sets, they are constrained in their form. The use of a bijective map for infinitesimal time evolution will lead us to Hamilton's equation. In this section we'll study a single degree of freedom, then extend in the next two section to multiple degrees of freedom and to the time dependent case.

\begin{defn}\label{canonical}
We call \emph{canonical transformation} a bijective map on $\mathbf{T}^*\mathbbm{Q}$.
\end{defn}

\begin{prop}\label{continuousMapping}
A canonical transformation must be continuous and preserve $\omega$.
\end{prop}

As we saw \ref{labelsCount}, a bijective map conserves the cardinality of labels. In the continuous case, it will conserve relative cardinality and therefore $\omega$. The map must be continuous in q: suppose it isn't, it would split some cells into two parts, a cell would not be mapped to one and only one other cell, the mapping would not be bijective. The reverse mapping must be continuous in q as well, or the inverse would not map to one and only one cell.
\begin{align*}
dq' &= \frac{\partial q'}{\partial q} dq + \frac{\partial q'}{\partial p} dp \\
dq &= \frac{\partial q}{\partial q'} dq' + \frac{\partial q}{\partial p'} dp'
\end{align*}
We can re-express $dp'$ in terms of $dq$ and $dp$, as the conservation of $\omega$ means the map is non-degenerate. All partial derivatives are well defined, and therefore the mapping is continuous in p as well.

\begin{cor}\label{sdofInvariant}
Let $v$ and $w$ be two vectors defined on the tangent space of $\mathbf{T}^*\mathbbm{Q}$ for one degree of freedom. Let
\begin{align*}
\omega_{a, b} = \left[
  \begin{array}{cc}
    0 & 1 \\
    -1 & 0 \\
  \end{array}
\right] \\
\end{align*}
then $v'^{a} \omega_{a, b} w'^{b}=v^{a} \omega_{a, b} w^{b}$ under a canonical transformation, where $a$ and $b$ represent component along coordinates $\xi^{a} \equiv \{q,p\}$.
\end{cor}

Here we are simply expressing $\omega$, $v$ and $w$ with their respective components and underlying the fact that $\omega$ defines the metric conserved under canonical transformations.

\begin{lem}\label{genAntisim}
Let $v$ and $w$ be two vectors. Let $v^{a} \omega_{a, b} w^{b}$ be an antisymmetric product conserved under a continuous transformation parameterized by $t$. We can then define a function $H$ such that given $S^{a} \equiv d_{t}\xi^{a}$ and $S_{b} \equiv S^{a} \omega_{a, b}$, we have $S_{a} = \partial_{a}H$.
\end{lem}

$S^{a}$ is the vector field that represents how the state variables change. Simply applying the vector transformation rules under continuous transformation we have:
\begin{align*}
v^{a} \omega_{a, b} w^{b} &= v'^{a} \omega_{a, c} w'^{b}  \\
&= (v^{a} + \partial_{c} S^{a} dt v^{c}) \omega_{a, b} ( w^{b} + \partial_{d} S^{b} w^{d} dt) \\
&= v^{a} \omega_{a, b} w^{b} + (\partial_{c} S^{a} v^{c} \omega_{a, b} w^{b} \\
 &+ v^{a} \omega_{a, b} \partial_{d} S^{b} w^{d}) dt + O(dt^2)
\end{align*}
\begin{align*}
v^{c} w^{b} \partial_{c} S_{b} - v^{a} w^{d} \partial_{d} S_{a} = 0
\end{align*}
\begin{align*}
\partial_{a} S_{b} - \partial_{b} S_{a} &= curl(S_{a}) = 0 \\
S_{a} &= \partial_{a}H
\end{align*}

\begin{prop}\label{sdofHam}
The time evolution for a single degree of freedom is given by:
\begin{align*}
d_{t}q &= \partial_{p} H \\
d_{t}p &= - \partial_{q} H
\end{align*}
\end{prop}

Simply expand \ref{genAntisim} with the metric defined in \ref{sdofInvariant}. We recognize Hamilton's equations for one degree of freedom\cite{classical_dynamics}.

\section{Multiple independent degrees of freedom}

\begin{prop}\label{mdofInvariant}
Let $v$ and $w$ be two vectors defined on the tangent space of the phase space $\mathbf{T}^*\mathbbm{Q}$ for two independent degrees of freedom. Let $a$ and $b$ be indexes for the state variables $\xi^a\equiv \{q^i, p_i\}$. Let
\begin{align*}
\omega_{\alpha, \beta} =  \left[
  \begin{array}{cc}
    0 & 1 \\
    -1 & 0 \\
  \end{array}
\right] \otimes \left[
  \begin{array}{cc}
    1 & 0 \\
    0 & 1 \\
  \end{array}
\right] =
\left[
  \begin{array}{cccc}
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1 \\
    -1 & 0 & 0 & 0 \\
    0 & -1 & 0 & 0 \\
  \end{array}
\right] \\
\end{align*}
then $v'^{a} \omega_{a, b} w'^{b}=v^{a} \omega_{a, b} w^{a}$ under a canonical transformation.
\end{prop}

The independence between degrees of freedoms corresponds to orthogonality in phase space: from \ref{labelsCombine} the product between the number of labels on each d.o.f. (i.e. the area), must be equal to the number of combines labels (i.e. the hyper-volume), which is true only if the d.o.f are orthogonal in phase space. From \ref{labelsCount}, the mapping will preserve the cardinality of labels, the area\footnote{We assume we are using the same unit across d.o.f.} on each d.o.f, and the independence, orthogonality across d.o.f.\footnote{These statements provide a direct physical interpretation for Gromov's non-squeezing theorem\cite{Gromov,deGosson,Stewart}.} This is equivalent to requiring the conservation of the scalar product across independent degrees of freedom, while still requiring conservation of the vector product within. That leads us to the metric defined by \ref{mdofInvariant}.
The metric generalizes \ref{sdofInvariant} to give us the cardinality of labels defined on the area given by two arbitrary directions in phase space. For an infinitesimal region, this corresponds to $dq^1 \wedge dp_1 + dq^2 \wedge dp_2$, the sum of the projections on the independent planes. Moreover, volume in phase space corresponds to the cardinality of the combined labels (i.e. the states), and is therefore conserved: this is Liouville's theorem for Hamiltonian mechanics.

\begin{prop}\label{mdofHam}
The evolution for multiple degrees of freedom is given by:
\begin{align*}
d_{t}q^i &= \partial_{p_i} H \\
d_{t}p_i &= - \partial_{q^i} H
\end{align*}
\end{prop}

Expand \ref{genAntisim} with the metric defined in \ref{mdofInvariant}. We recognize Hamilton's equations for multiple degrees of freedom\cite{classical_dynamics}.

\section{Time dependence}

So far we have assumed that neither state labeling nor mapping change in time. If they do, we also need to to use time as a label and therefore introduce an extra degree of freedom.

\begin{defn}\label{tdof}
The \emph{temporal degree of freedom} is a state variable identified by temporal cells. The center of each cell is identified by $t$, the width by $\omega dt$, the conjugate variable $E\equiv\hbar\omega$. We call \emph{extended phase space} the outer product between phase space and the temporal degree of freedom.
\end{defn}

\begin{prop}\label{tdofMonotonic}
Let $s$ be the parameter of a trajectory in the extended phase space of a deterministic and reversible system. The trajectory must be continuous. There must exist a strictly monotonic function $t(s)$.
\end{prop}

The trajectory has to be continuous in both standard and temporal variables because of \ref{continuousMapping}. Since determinism and reversibility are defined in time, the trajectory must traverse all times once and only once: we must have an invertible mapping between $t$ and $s$, which means we must have a strictly monotonic $t(s)$.

\begin{defn}\label{tdofAntistates}
We call \emph{standard states} those connected by a trajectory where $d_{s}t>0$. We call \emph{anti-states} those connected by a trajectory where $d_{s}t<0$.
\end{defn}

Since $t(s)$ is strictly monotonic, $d_{s}t$ along a trajectory cannot change sign, so we have the division between standard and anti-states. Note that since the parametrization is conventional and can be changed to $s'=-s$, what we call standard and anti-states is also conventional. What is physical and not conventional, though, is that standard and anti-states cannot be connected by deterministic and reversible evolution.\footnote{This represents a classical analogue for quantum anti-particle states.}

\begin{prop}\label{tdofInvariant}
Let $\mathcal{M}\equiv\mathbbm{T}\times\mathbbm{Q}$ the configuration manifold extended by time. Let $v$ and $w$ be two vectors defined on the tangent space of extended phase space $\mathbf{T}^*\mathcal{M}\equiv\mathbf{T}^*\mathbbm{T}\times\mathbf{T}^*\mathbbm{Q}$ for the temporal degree of freedom and one standard degree of freedom. Let $a$ and $b$ be indexes for the state variables $\xi^a\equiv\{t, q, E, p\}$. Let
\begin{align*}
\omega_{a, b} =  \left[
  \begin{array}{cc}
    0 & 1 \\
    -1 & 0 \\
  \end{array}
\right] \otimes \left[
  \begin{array}{cc}
    -1 & 0 \\
    0 & 1 \\
  \end{array}
\right]
= \left[
  \begin{array}{cccc}
    0 & 0 & -1 & 0 \\
    0 & 0 & 0 & 1 \\
    1 & 0 & 0 & 0 \\
    0 & -1 & 0 & 0 \\
  \end{array}
\right] \\
\end{align*}
then $v'^{a} \omega_{a, b} w'^{b}=v^{a} \omega_{a, b} w^{b}$ under deterministic and reversible evolution.
\end{prop}

$\langle t, E \rangle$ are not independent from $\langle q, p \rangle$ as they do not define new states. So they are not necessarily orthogonal in the extended phase space. States are defined on the plane where $\langle q, p \rangle$ (maximally) change: this is not the plane of constant $\langle t, E \rangle$ (they are not orthogonal) where $dq \wedge dp$ is defined, but the plane perpendicular to constant $\langle q, p \rangle$ where $dt \wedge dE$ is defined. On that plane we can properly count states and define our invariant.

We have a right triangle-like relationship between the plane where the invariant is defined and its projections on the planes defined by each d.o.f., similar to the multiple d.o.f.:
\begin{align*}
m.d.o.f \;\;\; &dq^1 \wedge dp_1 + dq^2 \wedge dp_2 = k \\
t.d.o.f \;\;\; &dt \wedge dE + k = dq \wedge dp \\
\end{align*}
But in the previous case, the right angle was between the two independent d.o.f.. In this case, the right angle is between the invariant and the plane of constant $\langle q, p \rangle$ where $dt \wedge dE$ is defined. We rewrite it as $dq \wedge dp - dt \wedge dE = k$. This corresponds to the Minkowski product across d.o.f. and the vector product within. The metric, with a space-like convention, still gives us the cardinality of labels within a degree of freedom, adjusting \ref{sdofInvariant} to avoid "double counting".

\begin{prop}\label{tdofHam}
The evolution for time varying multiple degrees of freedom is given by:
\begin{align*}
d_{s}t &= - \partial_{E} \mathcal{H} \\
d_{s}E &= \partial_{t} \mathcal{H} \\
d_{s}q^i &= \partial_{p_i} \mathcal{H} \\
d_{s}p_i &= - \partial_{q^i} \mathcal{H}
\end{align*}
\end{prop}

Take the metric from \ref{tdofInvariant}, add multiple independent d.o.f as in \ref{mdofInvariant}, use \ref{genAntisim} with the parameter $s$ instead of $t$ and generator $\mathcal{H}$ instead of $H$.

If we set\footnote{We avoided using $p^{n+1}$ as it hides the minus sign from the metric, making it seem that the temporal d.o.f is just another independent d.o.f.} $q^{n+1}=t$ and $p^{n+1}=-e$, we recognise Hamilton equations in the extended phase space\footnote{As in Struckmeier\cite{Struckmeier}, $d_{s}t$ need not be unitary.}\cite{Synge,Lanczos}.

\begin{prop}\label{tdofConstrain}
The evolution is constrained by $\mathcal{H}=k$.
\end{prop}

Since $\mathcal{H}$ is constant through the evolution, it can serve both as the generating function and as the evolution constraint. By convention, we can set $\mathcal{H}=0$ without loss of generality as changing $\mathcal{H}$ by a constant does not change the equation of motion. This reduces extended phase space to $2N + 1$ components, the state variables plus time.

\section{Kinematics}
It's now time to turn our attention to the configuration manifold $mathbbm{Q}$, as what we are really interested in studying is the motion of bodies in physical space. As the trajectories go through time as well, we will directly study the time dependent case on the extended configuration manifold $mathcal{M}$.

We will introduce another assumption: that the trajectories are enough to fully describe the system. We can expect this to hold true if the system is elemental (it has no internal structure) and is sufficiently isolated. At that point, if the motion is the result of a deterministic and reversible process, no two trajectories can be attributed to the same state as there is nothing else that could affect them.

\begin{assump3}\label{kinematicAssumption}
The study of the trajectory (kinematic) of a body is equivalent to study its state (dynamic) under deterministic and reversible evolution.
\end{assump3}

\begin{cor}\label{}
Given all possible trajectories $x^\alpha(s)$ in the extended configuration manifold $\mathcal{M}$ and all possible trajectory $\xi^a(s)$ in the extended phase space $\mathbf{T}^*\mathcal{M}$, there exist a bijective function $f: x^\alpha(s) \leftrightarrow \xi^a(s)$ that links each space-time trajectory with one and only one phase space trajectory.
\end{cor}

If studying the motion and state evolution are equivalent, then we must be able to go back and forth between the two pictures. Without losing generality, we can chose $x^\alpha=f(q^i,t)$ to be a function of only $q^i$ and $t$.

\begin{prop}\label{locallyMinkowski}
The space-time extended configuration manifold $\mathcal{M}$ is a locally Minkowskian Riemannian manifold. That is, there exists a metric $g$ that at any point can be expressed, with a suitable choice of coordinate, as $dx^\alpha g_{\alpha \beta}(P) dx^\beta=dx^\alpha\eta_{\alpha \beta}dx^\beta=(dx^i)^2 - (dx^0)^2=(dx^i)^2 - c^2dt^2$, where $c=n(dq)/n(dt)$ is the ratio between the density of states in space and time.
\end{prop}

As states are defined on intervals, a metric $g$ must be defined on $\mathcal{M}$. Such a metric must be consistent with $\omega$ as defined on $\mathbf{T}^*\mathcal{M}$, as both must be invariant under coordinate transformations. The idea is that each $(dx^\alpha)^2$ can be made to both represent a length square in space-time and an area in phase space, linking the two metrics. For each spatial d.o.f. fix $dp_i=\lambda dq^i$, we have $dq^i \wedge dp_i = \lambda (dq^i)^2$ where $\lambda$ converts from length squared to the label cardinality contained in the area. For the temporal d.o.f fix $dE = \lambda c^2 dt$, we have $dt \wedge dE = \lambda c^2 dt^2$. That is: the area in time squared is converted to an area in length squared that have the same density of states (as per definition of $c$) and then to label cardinality. The phase space invariant is $\omega = \lambda [(dq^i)^2 - c^2 dt^2]$.

Assume the choice of coordinates $x^\alpha$ locally diagonalizes $g(x^\alpha)$, each diagonal element being either $\pm 1$ (such coordinate system always exists). Set $x^i=q^i$ and $x^0=ct$. We have $\omega = \lambda ((dx^i)^2 - (dx^0)^2)$ and $dx^\alpha g_{\alpha \beta} dx^\beta=dx^\alpha g_{\alpha \alpha}dx^\alpha$. Both are invariant under coordinate transformation for any $dx^\alpha$. This can only be if $g_{ii}(x^\alpha)=1$ and $g_{00}(x^\alpha)=-1$.

It is fitting that deterministic and reversible evolution requires space-time to be locally Minkowskian, as this clearly defines past and future events. To make us understand better the role of $c$, as we defined it, we prove the following.

\begin{prop}\label{locallyMinkowski}
The speed of a body cannot exceed $c$ under the kinematic equivalence assumption.
\end{prop}

Consider a movement $ds$ along any trajectory. This will go through $n(dt)$ labels in time and $n(dq)$ labels in space. As the motion is continuous, the number of labels in space cannot exceed the number of labels in time, we can't skip them, therefore $n(dq)\leq c n(dt)$. So we have:
\begin{align*}
\frac{n(dq)}{n(dt)}= \frac{dq}{dt} \leq c \\
\end{align*}

\begin{prop}\label{initialConditions}
Let $x^\alpha={ct, q^i}$ and $u^\alpha = d_s x^\alpha$ be the four-velocity, where the parametrization $s$ is chosen, by convention, to be proper time. The position $x^\alpha$ and velocity $u^\alpha$ are necessary and sufficient initial conditions to determine the state of the system and its whole trajectory.
\end{prop}

As the equation of motion \ref{tdofHam} can be at most second order in $\{t, q^i\}$, they can at most be second order in $x^\alpha=\{ct, q^i\}$ so only position and velocity can be candidates for the initial conditions. Fixing time, phase space is $\mathbbm{R}^{2n}$, too big to be covered by position only, but just right to be covered by both.

\begin{defn}\label{inertialMass}
Let $dp_\alpha$ an infinitesimal interval of conjugate momentum and $d(g_{\alpha \beta}u^\beta)$ an infinitesimal interval of the covariant components of the four velocity. The ratio $m=n(dp_\alpha)/n(d(g_{\alpha \beta}u^\beta))$ between their relative label cardinality is called \emph{inertial mass}.
\end{defn}

\begin{prop}\label{kineticMomentum}
Let $x^\alpha=\{ct, q^i\}$ and $p_\alpha=\{-E/c, p_i\}$. Then $p_\alpha= m g_{\alpha \beta}u^\beta + \hat{p}_\alpha(x^\gamma)$, where $\hat{p}_\alpha : \mathcal{M} \rightarrow \mathbbm{R}$ is a function defined on the extended configuration manifold.
\end{prop}

Given \ref{initialConditions}, there must exist $p_\alpha=p_\alpha(x^\beta , u^\gamma)$. We express it in terms of $u_\alpha\equiv g_{\alpha \beta} u^\beta$. We have:
\begin{align*}
\omega &= q^i\wedge p_i - ct \wedge E/c \\
&=x^\alpha \wedge p_\alpha \\
&=dx^\alpha \wedge \frac{\partial p_\alpha}{\partial u_\beta}du_\beta + dx^\alpha \wedge \frac{\partial p_\alpha}{\partial x^\gamma}dx^\gamma \\
&=\frac{\partial p_\alpha}{\partial u_\beta}du_\beta dx^\alpha \\
\end{align*}
Consider the expression $m du_\alpha dx^\alpha$: this invariant gives us the density of labels in position and velocity converted to the conjugate variables. That is: $\omega=m du_\alpha dx^\alpha$. Combining the two:
\begin{align*}
\frac{\partial p_\alpha}{\partial u_\beta} &= m \delta^\beta_\alpha \\
p_\alpha &= m g_{\alpha \beta}u^\beta + \hat{p}_\alpha(x^\gamma)
\end{align*}
where $\hat{p}$ is an arbitrary function.

To convince ourselves that $m$ is indeed the inertial mass, consider applying a force. We are changing the state through the velocity, meaning changing the conjugate momentum. The higher the mass, the more states we'll have to go through to reach the same velocity. The higher the mass, the more change is required, the more force needs to be applied.

\begin{prop}\label{kineticHamiltonian}
The extended Hamiltonian is $\mathcal{H}=\frac{1}{2m}(p_\alpha-\hat{p}_\alpha(x))g^{\alpha\beta}(p_\beta-\hat{p}_\beta(x))+\hat{\mathcal{H}}(x)$, where $\hat{\mathcal{H}}_\alpha : \mathcal{M} \rightarrow \mathbbm{R}$ is a function defined on the extended configuration manifold.
\end{prop}
We have:
\begin{align*}
\frac{dq^\alpha}{ds} &= u^\alpha \\
&= \frac{1}{m}g^{\alpha\beta}(p_\beta-\hat{p}_\beta) \\
&= \frac{\partial \mathcal{H}}{dp_\alpha} \\
\end{align*}
Integrating we have the expression for the Hamiltonian, where $\hat{\mathcal{H}}$ is an arbitrary function.

Now that we have found the general form of the Hamiltonian, we show that this is compatible with the established fundamental classical theories.

\begin{prop}\label{relativisticEM}
Let $\hat{p}_\alpha = q A_\alpha$, $F_{\alpha \beta} \equiv \partial_\alpha A_\beta - \partial_\beta A_\alpha$ and $\hat{H} = 0$, the equations of motion are $m \nabla_u u^\alpha = g^{\alpha\beta} F_{\beta \gamma} q u^\gamma$. These are the relativistic equations for a charged particle.
\end{prop}

We first derive the following relationship for later use:
\begin{align*}
\partial_\alpha \delta^\beta_\gamma &= 0 = \partial_\alpha g^{\beta\delta} g_{\delta\gamma} + g^{\beta\delta} \partial_\alpha g_{\delta\gamma}\\
\partial_\alpha g^{\beta\epsilon} &= - g^{\beta\delta} g^{\gamma\epsilon} \partial_\alpha g_{\delta\gamma}
\end{align*}

We expand \ref{tdofHam} using \ref{kineticHamiltonian}:
\begin{align*}
u^\alpha &= \frac{dq^\alpha}{ds} = \frac{\partial \mathcal{H}}{dp_\alpha} \\
&= \frac{1}{m}g^{\alpha\beta}(p_\beta-\hat{p}_\beta) \\
d_s p_\alpha &= - \frac{\partial \mathcal{H}}{\partial q^\alpha} \\
&=\frac{1}{2m}[\partial_\alpha \hat{p}_\beta g^{\beta \gamma} (p_\gamma -\hat{p}_\gamma) \\
 &- (p_\beta -\hat{p}_\beta) \partial_\alpha g^{\beta \gamma} (p_\gamma -\hat{p}_\gamma) \\
 &+ (p_\beta -\hat{p}_\beta) g^{\beta \gamma} \partial_\alpha \hat{p}_\gamma ]- \partial_\alpha \hat{H} \\
&=\frac{1}{2}[\partial_\alpha \hat{p}_\beta u^\beta
- m u^\delta g_{\delta\beta} \partial_\alpha g^{\beta \gamma} u^\epsilon g_{\epsilon\gamma}
+ u^\gamma \partial_\alpha \hat{p}_\gamma ]- \partial_\alpha \hat{H}
\end{align*}

We then calculate the four-force:
\begin{align*}
m d_s u^\alpha &= d_s g^{\alpha\beta}(p_\beta-\hat{p}_\beta) + g^{\alpha\beta} d_s (p_\beta-\hat{p}_\beta) \\
&= \partial_\gamma g^{\alpha\beta} d_s x^\gamma m g_{\beta \delta} u^\delta + g^{\alpha\beta} (d_s p_\beta - \partial_\gamma \hat{p}_\beta d_s x^\gamma) \\
&= \partial_\gamma g^{\alpha\beta} u^\gamma m g_{\beta \delta} u^\delta + g^{\alpha\beta} \frac{1}{2} [\partial_\beta \hat{p}_\gamma u^\gamma
- m u^\epsilon g_{\epsilon\gamma} \partial_\beta g^{\gamma \delta} u^\zeta g_{\zeta\delta} \\
&+ u^\delta \partial_\beta \hat{p}_\delta ]- g^{\alpha\beta} \partial_\beta \hat{H} - g^{\alpha\beta} \partial_\gamma \hat{p}_\beta u^\gamma \\
&= m  g_{\beta \delta} \partial_\gamma g^{\alpha\beta} u^\gamma u^\delta - \frac{1}{2} m g^{\alpha\beta} g_{\zeta\delta} g_{\epsilon\gamma} \partial_\beta g^{\gamma \delta} u^\epsilon u^\zeta  \\
&+ g^{\alpha\beta} \partial_\beta \hat{p}_\gamma u^\gamma - g^{\alpha\beta} \partial_\gamma \hat{p}_\beta u^\gamma
- g^{\alpha\beta} \partial_\beta \hat{H}\\
&= - m  g^{\alpha \beta} \partial_\gamma g_{\beta\delta} u^\gamma u^\delta + \frac{1}{2} m g^{\alpha\beta} \partial_\beta g_{\gamma \delta} u^\gamma u^\delta  \\
&+ g^{\alpha\beta} (\partial_\beta \hat{p}_\gamma - \partial_\gamma \hat{p}_\beta ) u^\gamma
- g^{\alpha\beta} \partial_\beta \hat{H}\\
&= - m \frac{1}{2} g^{\alpha \beta} ( \partial_\gamma g_{\beta\delta} + \partial_\delta g_{\beta\gamma} - \partial_\beta g_{\gamma \delta} ) u^\gamma u^\delta  \\
&+ g^{\alpha\beta} (\partial_\beta \hat{p}_\gamma - \partial_\gamma \hat{p}_\beta ) u^\gamma
- g^{\alpha\beta} \partial_\beta \hat{H}\\
&= - m \Gamma ^\alpha_{\ \gamma \delta} u^\gamma u^\delta + g^{\alpha\beta} (\partial_\beta \hat{p}_\gamma - \partial_\gamma \hat{p}_\beta ) u^\gamma
- g^{\alpha\beta} \partial_\beta \hat{H}
\end{align*}
\begin{align*}
m \nabla_{u} u^\alpha &= m (d_s u^\alpha + \Gamma ^\alpha_{\ \gamma \delta} u^\gamma u^\delta)  \\
&= g^{\alpha\beta} (\partial_\beta \hat{p}_\gamma - \partial_\gamma \hat{p}_\beta ) u^\gamma - g^{\alpha\beta} \partial_\beta \hat{H}\\
&= g^{\alpha\beta} (\nabla_\beta \hat{p}_\gamma - \nabla_\gamma \hat{p}_\beta ) u^\gamma - g^{\alpha\beta} \nabla_\beta \hat{H}
\end{align*}

The equation is manifestly covariant. If $\hat{p}$ and $\hat{H}$ are zero, absence of forces, we recognize the geodesic equation. We substitute $\hat{p}_\alpha = q A_\alpha$ and $\hat{H} = 0$ and have:

\begin{align*}
m \nabla_{u} u^\alpha &= g^{\alpha\beta} (\partial_\beta A_\gamma - \partial_\gamma A_\beta ) q u^\gamma \\
&= g^{\alpha\beta} F_{\beta \gamma} q u^\gamma\\
\end{align*}

This is indeed compatible with general relativity and classical electro-magnetism.

\begin{prop}\label{newtonianGravitation}
Assume $\mathcal{M}$ flat and time independent motion, the Hamiltonian simplifies to $H=\frac{1}{2m}(p_i-\hat{p}_\alpha(x))^2)+\hat{H}(x)$. Let $\hat{p}_i = 0$ and $\hat{H} = mV$, the equations of motion are $m d_t v^i = - m \partial_i V$, where $v^i=dx^1/dt$. These are equations for a particle under a Netwonian gravitational potential.
\end{prop}

Given flat space-time and time independent motion, we can use $t$ as a parameter for the motion in $\mathbbm{Q}$. Repeating \ref{kineticMomentum} and \ref{initialConditions} for the non-relativistic case leads to the above Hamiltonian. Similar to \ref{relativisticEM}, use \ref{mdofHam} with the newly found Hamiltonian and find the equation of motion.

\begin{defn}\label{lagrangian}
Let $\mathcal{H}$ be an extended hamiltonian defined on $\mathbf{T}^*\mathcal{M}$. Under the kinetic assumption, we can define the Legendre transform $\mathcal{L}=u^\alpha p_\alpha - \mathcal{H}$ which we call \emph{extended Lagrangian}. For the time invariant case, we define the \emph{Lagrangian} $L=u^\alpha p_\alpha - H$.
\end{defn}

The Legendre transform can be defined only if $\mathcal{H}$ is convex in $p_\alpha$. The Hamiltonian found at \ref{kineticHamiltonian} is convex, so the Lagrangian can always be defined. While the kinetic equivalence assumption is sufficient, it's not necessary. What is necessary is \ref{initialConditions}: as long as position and velocity are enough to determine the state, $u^\alpha=f(q^\alpha, p_\alpha)$ must be monotonic in $p_\alpha$, which means $\mathcal{H}$ is convex in $p_\alpha$. What happens in that case is that the space-time trajectories may become more or less dense, $du_\alpha$ and $dx^\alpha$ would not be enough to define the label cardinality and therefore the state density $\rho$. In short: deterministic and reversible evolution gives us Hamiltonian mechanics, position and velocity as initial conditions Lagrangian mechanics, and the kinetic assumption (which links the differentials of state variables and initial conditions) gives us the narrowed Hamiltonian form.

\section{Conclusion}

As we have touched many areas, we could only scratch the surface. There are many more details that can be expanded upon. Yet, the intent is just to give the overall picture, which could be summarized in the following points.

\begin{itemize}
  \item Classical states are those that describe every infinitesimal part.
  \item Classical particles are infinitesimal cells. Phase space is the cotangent bundle $\mathbf{T}^*\mathbbm{Q}$ because that's the space of infinitesimal cells.
  \item Hamiltonian mechanics coincides with deterministic and reversible evolution.
  \item Hamiltonian flow is the conservation of number of labels for each independent degree of freedom.
  \item The conservation of number of states is what ultimately gives space-time its locally Minkowskian nature.
  \item Lagrangian mechanics coincides with position and velocity being necessary and sufficient initial conditions.
  \item The motion of an isolated elementary system, for which the kinetic assumption is valid, is restricted to a Hamiltonian that can describe fundamental classical forces.
\end{itemize}

This helps clarify and understand much of the classical framework in a more cohesive way. The notion of cardinality of labels and states is what's at the heart.

While this is limited to classical particle mechanics, it should be obvious how, at least in principle, this work could be extended. For field theories, the \emph{kinematic assumption} should be substituted by a \emph{kinematic field assumption}: what we are studying are not trajectories $x^\alpha(s)$ but fields $\psi(x^\alpha)$. The field values at each point become a set of independent state variables, where their conjugates $\pi(x^\alpha)$ will be linked to $d_s\psi(x^\alpha)$. For quantum mechanics, the \emph{infinite reducibility assumption} has to leave way to an \emph{irreducibility assumption}: the state of parts of a quantum system cannot be known. The configuration state as a whole undergoes deterministic and reversible evolution, while the motion of its parts does not: it is non deterministic.

The hope is that, by continuing in this approach, we can shed more light on why the laws of physics are what they are; and show that they are not arbitrary rules, but necessary given few simple assumptions.

\begin{thebibliography}{0}

\bibitem{Jaynes} Jaynes, E. T.: ``Information theory and statistical mechanics'', (1963)
\bibitem{Shannon} Shannon, C. E.: ``A mathematical theory of communications'', The Bell System Technical Journal, Vol. 27, pp. 379–423, 623–656, (1948)
\bibitem{classical_dynamics} J. V. Jose', E. J. Saletan: ``Classical Dynamics'', Cambridge University Press, (1998)
\bibitem{Gromov} Gromov, M. L.: ``Pseudo holomorphic curves in symplectic manifolds''. Inventiones Mathematicae 82: 307–347, (1985)
\bibitem{deGosson} de Gosson, M. A.: ``The symplectic camel and the uncertainty principle: the tip of an iceberg?'', Foundation of Physics 39, pp. 194–214, (2009)
\bibitem{Stewart} Stewart, I.: ``The symplectic camel'', Nature 329(6134), 17–18 (1987)
\bibitem{Lanczos} Lanczos, C.: ``The variational principles of mechanics'', University of Toronto Press (1949)
\bibitem{Synge} Synge, J. L.: Encyclopedia of Physics Vol 3/1, Springer (1960)
\bibitem{Struckmeier} Struckmeier, J.: ``Hamiltonian dynamics on the symplectic extended phase space for autonomous and non-autonomous systems'', J. Phys. A: Math. Gen 38, 1257-1278, (2005)

\end{thebibliography}

\end{document}
