\documentclass[aps,pra,10pt,twocolumn,floatfix,nofootinbib]{revtex4-1}

\usepackage{bbm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{amsfonts}
\usepackage{amsthm}

\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}

\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem*{assump1}{Classical assumption}
\newtheorem*{assump2}{Determinism and Reversibility assumption}
\newtheorem*{assump3}{Kinematic assumption}

\begin{document}

\title{From physical principles to relativistic classical Hamiltonian and Lagrangian particle mechanics}
\author{Gabriele Carcassi}
\affiliation{University of Michigan, Ann Arbor, MI 48109}
\email{carcassi@umich.edu}
\date{June 16, 2014}

\begin{abstract}
We introduce three fundamental principles (infinite reducibility, deterministic and reversible evolution, ) and show that classical mechanics can be derived them. The core idea is that deterministic and reversible systems preserve the number of labels we use to identify states, which puts considerable constraints and leads to the Hamiltonian and Lagrangian frameworks, space-time being locally Minkowskian, the general form of the Hamiltonian and equations of motion equivalent to those for relativistic charged particles. Many familiar fundamental concepts and constants (such as mass, the speed of light, the Plank constant, the vector potential) are introduced and defined in a novel way, thus providing different insight into them. The derivation strives to use definition and mathematical concepts that would allow a future extension to quantum mechanics.\end{abstract}
\maketitle

\section{Introduction}
Classical mechanics is usually founded on Newton's laws. These, though, are insufficient to derive the Lagrangian and Hamiltonian formalism, and usually other ad-hoc assumptions (e.g. conservative forces) are introduced. Special relativity is based on two principles (invariance of the speed of light and the principle of relativity), which lead to the Minkowskian nature of space-time but not to the equation of motion, which are a consistent reformulation of the non-relativistic ones. What we'll do in this work is see if we can re-organize all the known elements and equations in a more consistent and comprehensive way. The hope is that this gives us better insight on why the fundamental laws are what they are. Also, given that classical and quantum mechanics are formally equivalent, there is a chance that such work could be extended to quantum mechanics.

We'll first mathematically define states and the labels (e.g. position, momentum, temperature, pressure) we use to identify them. Using the principle of infinite reducibility (or classical assumption), the idea that each state is always divisible into the states of its sub-systems, we show that it is sufficient to describe the evolution of infinitesimal subsystem within their state space (or phase space).

Under the assumption of deterministic and reversible evolution, to each state corresponds one and only one future (or past) state, we show that the cardinality of labels (and states) is conserved. This allows us to define a metric on phase space, and the conservation of that metric leads to the Hamiltonian framework. That is: we can derive the Hamiltonian framework on its own merit and show that it is equivalent to deterministic and reversible motion.

We then introduce the principle of kinematic equivalence, the idea that studying trajectories is equivalent to studying states, and show that under this assumption we can define a transformation between state and kinematic variables. Noting that a passive coordinate change in space-time is equivalent to a re-labelling of states, and as such should conserve the phase space metric (i.e. the cardinality of states), the metric of space-time is constrained to be locally Minkowskian. Under the kinematic equivalence, the relationship between velocity and conjugate momentum has to be monotonic, leading to a concave Hamiltonian which allows a Legendre transformation leading to the Lagrangian. We can constrain the Hamiltonian further, and show that the most general form of motion under the three condition is the one of a geodesics modified by the force given by a vector potential, such as the one of a relativistic charged particle.

The above outline should help the reader maintain the big picture, as each section will go through the many details and definitions. We'll keep names and notation as consistent as possible to current use, but this may lead to some non sequitur as it will not be immediately clear why the different definition will be at the end equivalent to the standard one. This is still preferable than introducing a whole new set of names one has to become familiar.

While we try to keep a precise language, no mathematical breakthrough should be expected: the goal, after all, is to derive the \emph{known} framework from a set of \emph{simple} definitions in the most \emph{obvious} way possible. No proof is longer than a couple of paragraphs, so the word \emph{theorem} is avoided in favor of \emph{proposition} and \emph{corollary}. The novel, and surprising, result is how so much can be derived from so little.

\section{States, Labels and Maps}

The first two sections are dedicated to properly introduce states and the labels we use to identify them (such as position or temperature). The two issues that needs to be clarified are the nature of the system described (whole system vs infinitesimal component) and the cardinality of the states (discrete vs continuous variables). When talking about infinitesimal components and continuous labels, in fact, one must always remember that they are the result of a limit. Failure to do so would result in improper characterization of the system or counting of labels. We start with the whole system and discrete labels, then study the two limits separately.\footnote{Whole system vs infinitesimal component is also source of confusion when comparing classical and quantum states. Quantum states are always whole systems and are always distributions as there is no state uniquely attributed to its infinitesimal components.}

\begin{defn}\label{statedef}
Suppose we have a physical system to study. We define the set $\mathbbm{C}$ of all physically distinguishable configurations for that system. Each element $\mathbbm{c}$ we call \emph{configuration state}.
\end{defn}

\begin{assump1}\label{classical}
The system is infinitely reducible: it can be thought as composed by two or more similar but smaller systems, each in its own configuration state, which also can be thought as composed by two or more, ad infinitum.
\end{assump1}

\begin{defn}\label{classicalPhaseSpace}
Let $\mathbbm{S}$ be the set of all possible configuration states of the infinitesimal subdivision. We call this set \emph{phase space}. We call each element $\mathbbm{s}$ a \emph{state}.
\end{defn}

\begin{cor}\label{classicalDistribution}
Each classical configuration state $\mathbbm{c} \in \mathbbm{C}$ is a distribution over states: $\mathbbm{c}=\sum\limits_{\mathbbm{s} \in \mathbbm{S}} D(\mathbbm{s}) \mathbbm{s}$, where $D:\mathbbm{S}\rightarrow\mathbb{R}$ measures how much of the system can be found in each $\mathbbm{s}$. The distribution can be visualized as a histogram over the states in phase space.
\end{cor}

Under the classical assumption, we can then limit ourselves to the study of the infinitesimal elements, their states and their properties without loss of generality. To help identify states, we introduce the following concepts.

\begin{defn}\label{label}
We call a \emph{label} a set of states $i\subset\mathbbm{S}$; a \emph{set of labels} a collection of disjoint labels $I | \forall i_1,i_2\in I, i_1\bigcap i_2 = \emptyset$; a \emph{state variable} a set of labels $X$ that covers all of phase space: $\bigcup\limits_{i \in X}i=\mathbbm{S}$. Therefore a state belongs to one and only one label of a state variable.
\end{defn}

\begin{defn}\label{labelsCombine}
Let $I_1$ and $I_2$ be two sets of labels. We can define the \emph{combined set}, $\langle I_1, I_2 \rangle$, whose labels consist of all the non-empty intersections of one label of $I_1$ and one of $I_2$. If all intersections are non-empty, $I_1$ and $I_2$ are said to be \emph{independent}, and we have $n(\langle I_1, I_2 \rangle)=n(I_1)n(I_2)$ where $n: I \rightarrow \mathbbm{R}$ gives the number of labels of each set.
\end{defn}

We now want to study how states and labels evolve in time, under the following assumption.

\begin{assump2}
The system undergoes deterministic (future state identified by the present state) and reversible (past state identified by the present state) evolution.
\end{assump2}

\begin{prop}\label{detrevMap}
Let $\mathbbm{S}$ be the phase space of a system that undergoes deterministic and reversible evolution. There exists a bijective map $f:\mathbbm{S} \leftrightarrow \mathbbm{S}$ between past and future states.
\end{prop}

\begin{cor}\label{detrevDist}
The evolution of a classical configuration state $\mathbbm{c}=\sum D(\mathbbm{s}) \mathbbm{s}$ under a bijective map is given by $\mathbbm{c'}=\sum D'(\mathbbm{s}) \mathbbm{s}=\sum D(f^{-1}(s)) \mathbbm{s}$. The evolution of the fraction of the system in a label $D(i)=\sum\limits_{\mathbbm{S} \in i} D(\mathbbm{s})$ is given by $D'(i)=D(f^{-1}(i))$.
\end{cor}

Mathematically, assuming determinism and reversibility means studying bijective maps. The evolution of a distribution simply moves the elements around: the bars of the histogram move place, but keep the same height.

\begin{cor}\label{labelsCount}
Given a label $i$, the image $f(i)$ is also a label containing the same number of states. Given a set of labels $I$, the image $f(I)$ is also a set of labels containing the same number of labels. Given a state variable $X$, the image $f(X)$ is also a state variable. Given two independent sets of labels $I_1$ and $I_2$, the images $f(I_1)$ and $f(I_2)$ are also independent. Therefore $n(f(\langle I_1, I_2 \rangle))=n(f(I_1))n(f(I_2))=n(I_1)n(I_2)=n(\langle I_1, I_2 \rangle)$
\end{cor}

Bijective maps preserve the number of labels as they provide one-to-one association between future and past. And they do so for each independent set of labels. These simple results using discrete labels, properly generalized to the continuous case, will give us Hamiltonian flow.


\section{Hamiltonian review}

\section{Kinematics}
\begin{assump3}\label{kinematicAssumption}
The study of the motion of a body is equivalent to study its state under deterministic and reversible evolution.
\end{assump3}

\begin{cor}\label{}
Consider all states at $t=t_0$ and all possible trajectories, to each state corresponds one and only one trajectory; to each trajectory corresponds one and only one state.
\end{cor}

If studying the motion and state evolution are equivalent, given a state we must be able to reconstruct the trajectory, and given the trajectory we must be able to reconstruct the state. Given that the choice of state coordinates is arbitrary, we can use position and time as a set of continuous state variables: $q^\alpha = x^\alpha$. With that in mind:

\begin{prop}\label{}
A metric $g_{\alpha\beta}$ must be defined on the manifold identified by $x^\alpha$. All trajectories must be continuous.
\end{prop}

As each label corresponds to an infinitesimal cell, we need distances properly defined. This requires a metric defined on the manifold. And since evolution is continuous on state variables, it will be continuous in $x^\alpha$ as well.

\begin{defn}\label{continuousLabels}
An \emph{inertial frame} is one for which each direction of space represents a homogeneous state variable of an independent degree of freedom.\footnote{While a local inertial frame always exists, the existence of a global one is an added requirement. We add it because it makes the discussion easier and the proofs more obvious. Most of the results, though, will hold without that assumption. This will be important in future works that will try to extend this framework to general relativity.}
\end{defn}

\begin{cor}\label{continuousLabels}
The metric associated with an inertial frame is
\begin{align*}
g_{\alpha, \beta} =  \left[
  \begin{array}{cccc}
    -1 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1 \\
  \end{array}
\right] \\
\end{align*}
\end{cor}

The relationships between coordinates is the same as in phase space: $X^i$ must be orthogonal with each other, as the corresponding $Q^i$ are orthogonal in phase space; $X^i$ and $X^0$ are not in general orthogonal and it is the length perpendicular to time that gets conserved. Given that $X^\alpha$ are homogeneous, the metric must be invariant under translation, does not change in space-time, it is constant. With a suitable choice of units, we can set $|g_{\alpha\alpha}|=1$. All these combines gives us the Minkowski metric. We also introduce a constant $c$\footnote{Here $c$ is not defined as a a speed: it's the constant that allows to convert the cardinality of labels between space and time coordinates.} to convert time intervals to space intervals with the same number of labels, so we have $x^0=ct$.

It's important to note that the geometry of extended phase space and the geometry of space-time are linked: we cannot define cells in one without also defining cells in the other. This is true for all reference frames, not just inertial ones.

\begin{prop}\label{continuousLabels}
The position $x^\alpha$ and the velocity $dx^i/dt$ are necessary and sufficient initial conditions to determine the state of the system and its whole trajectory.
\end{prop}

The initial conditions will be given by the position and its first $n$ derivatives: $x^i_k=d^kx^i(t_0)/dt^k$ where $k=0..n$. This means that there is a function that, given the initial conditions, gives us the trajectory: $x(t)=f(t_0, x^i_k)$. We note that the initial conditions can be changed by an active transformation, therefore counting the number of possible initial conditions is equivalent to counting the possible number of active transformations. Under such change, though, the metric cannot change: it needs to be a change in initial conditions in the same reference frame, or we would double count each case. Defining the transformation for the position also defines how all its derivatives change, and by requiring the invariance of the metric, our options are actually very limited. Assuming we start from an inertial frame, only a linear transformation in all $x^\alpha$ can preserve the metric. A linear transformation can only change position and velocity, so the initial condition can only be limited to those. We also note that the active transformation can always change the velocity of $x(t)$, so $f$ must depend on the velocity or it would not be able to reach all possible trajectories defined by an active transformation in the same reference frame. Therefore position and velocity are both necessary and sufficient initial condition.

\begin{prop}
Principle of relativity. The laws of motion have the same form for all inertial observers.
\end{prop}

We saw that an active transformation that does not change the metric is a change in the initial conditions. Such a change should not affect the form of the function that given the initial conditions gives us the whole trajectory: the observer is the same, the law of motion is the same, they just shift the value of the arguments. But if the form of the laws of motion is preserved under such active transformations, it will also not change under passive transformation that preserve the metric. Given that all inertial observers can be reached by a linear transformation, which preserves the metric, then the laws of motion will have the same form.

%x(t)=f(x_0, x_1, ... x_n)

%What is the space size for a particular frame?

%We can reach any initial condition by coordinate changes
%But they also change f
%Free parameters are going to be the ones we can change without changing f
%How many coordinate changes are available to use without changing f?
%The ones that preserve the metric

%l_\alpha^\gamma l_\beta^\delta g_{\gamma\delta} = g_{\alpha\beta}

%Suppose different coordinate frame with same metric
%x'(t)=f(x'_0, x'_1, ... x'_n)


Assume trajectory are deterministic and reversible. Have state.

How much state? Find that is two per degree of freedom. Position and momentum are only state variables.

Inertial frame

\section{Connect to Hamiltonian}
\begin{prop}\label{continuousLabels}
Under the kinematic assumption, there must exist a bijective transformation $q^\alpha=q^\alpha(x^\alpha,u^\alpha)$ and $p^\alpha=p^\alpha(x^\alpha,u^\alpha)$ between initial conditions and state variables. As such, they are monotonic in both variables.
\end{prop}

As we have seen, $X^\alpha$ and $U^\alpha$ are state variables that fully identify our degrees of freedom. Nothing tells us, though, that
they are conjugate variables. But, since for every set of initial condition there must be one and only one state associated with it. This means the transformation must be invertible, monotonic.

\begin{prop}\label{continuousLabels}
Under the kinematic assumption, the extended phase space is defined on the conjugate variables $q^\alpha=x^\alpha$ and $p_\alpha=m\frac{dx_\alpha}{ds}+\hat{p}_\alpha(x)$.
\end{prop}

Given the degree of arbitrariness in choice of transformation, we can set $q^\alpha=x^\alpha$. This creates a direct link between how space is measured ($g_{\alpha\beta}(x^\alpha)$) and the width of our cells in phase space ($m(q)$)

$\partial_\alpha \delta^\beta_\gamma = 0 = \partial_\alpha g^{\beta\delta} g_{\delta\gamma} + g^{\beta\delta} \partial_\alpha g_{\delta\gamma}$

$\partial_\alpha g^{\beta\delta} g_{\delta\gamma} = - g^{\beta\delta} \partial_\alpha g_{\delta\gamma}$

$\partial_\alpha g^{\beta\delta} g_{\delta\gamma} g^{\gamma\epsilon} = - g^{\beta\delta} \partial_\alpha g_{\delta\gamma} g^{\gamma\epsilon}$

$\partial_\alpha g^{\beta\epsilon} = - g^{\beta\delta} g^{\gamma\epsilon} \partial_\alpha g_{\delta\gamma} $

$p_\alpha=m\frac{dx_\alpha}{ds}+\hat{p}_\alpha(x)$


$\frac{dx^\alpha}{ds}=\frac{\partial H}{\partial p_\alpha}=\frac{1}{m}(p^\alpha-\hat{p}^\alpha(x))$

$H=\frac{1}{2m}(p_\alpha-\hat{p}_\alpha)g^{\alpha\beta}(p_\beta-\hat{p}_\beta(x))+\hat{H}(x)$

$\frac{dp_\alpha}{ds}=-\frac{\partial H}{\partial q^\alpha}=$

$\frac{1}{2m}[\partial_\alpha \hat{p}_\beta g^{\beta \gamma} (p_\gamma -\hat{p}_\gamma)
 - (p_\beta -\hat{p}_\beta) \partial_\alpha g^{\beta \gamma} (p_\gamma -\hat{p}_\gamma)
 + (p_\beta -\hat{p}_\beta) g^{\beta \gamma} \partial_\alpha \hat{p}_\gamma ]- \partial_\alpha \hat{H}(x)=$

$\frac{1}{2}[\partial_\alpha \hat{p}_\beta u^\beta
- m u^\delta g_{\delta\beta} \partial_\alpha g^{\beta \gamma} u^\epsilon g_{\epsilon\gamma}
+ u^\gamma \partial_\alpha \hat{p}_\gamma ]- \partial_\alpha \hat{H}(x)=$

$\partial_\alpha \hat{p}_\beta u^\beta + \frac{m}{2}u^\beta \partial_\alpha g_{\beta \gamma} u^\gamma
- \partial_\alpha \hat{H}(x)=$

$m\frac{d^2x_\alpha}{ds^2}+\frac{d\hat{p}_\alpha(x)}{ds}$

$m\frac{d^2x_\alpha}{ds^2}=\frac{1}{2}[\frac{\partial\hat{p}_\beta(x)}{\partial x^\alpha} (\frac{dx^\beta}{ds}) + (\frac{dx_\beta}{ds})\frac{\partial\hat{p}^\beta(x)}{\partial x^\alpha} ]-\frac{\partial\hat{p}_\alpha(x)}{\partial x^\beta}\frac{dx^\beta}{ds}
-\frac{\partial \hat{H}(x)}{\partial x^\alpha}$

$m\frac{d^2x_\alpha}{ds^2}=(\frac{\partial\hat{p}_\beta(x)}{\partial x^\alpha} - \frac{\partial\hat{p}_\alpha(x)}{\partial x^\beta} ) \frac{dx\beta}{ds}
-\frac{\partial \hat{H}(x)}{\partial x^\alpha}$

Find that p must be contra-variant. Must be monotonic. And a linear transformation of v. Introduce mass. Introduce gauge.

\section{Lagrangian}

From Hamiltonian conservation to Lagrangian. p monotonic means convex Hamiltonian: can use Legendre transform.

\section{Conclusion}

\begin{thebibliography}{0}

\bibitem{Jaynes} Jaynes, E. T.: ``Information theory and statistical mechanics'', (1963)
\bibitem{Shannon} Shannon, C. E.: ``A mathematical theory of communications'', The Bell System Technical Journal, Vol. 27, pp. 379–423, 623–656, (1948)
\bibitem{classical_dynamics} J. V. Jose', E. J. Saletan: ``Classical Dynamics'', Cambridge University Press, (1998)
\bibitem{Gromov} Gromov, M. L.: ``Pseudo holomorphic curves in symplectic manifolds''. Inventiones Mathematicae 82: 307–347, (1985)
\bibitem{deGosson} de Gosson, M. A.: ``The symplectic camel and the uncertainty principle: the tip of an iceberg?'', Foundation of Physics 39, pp. 194–214, (2009)
\bibitem{Stewart} Stewart, I.: ``The symplectic camel'', Nature 329(6134), 17–18 (1987)
\bibitem{Lanczos} Lanczos, C.: ``The variational principles of mechanics'', University of Toronto Press (1949)
\bibitem{Synge} Synge, J. L.: Encyclopedia of Physics Vol 3/1, Springer (1960)
\bibitem{Struckmeier} Struckmeier, J.: ``Hamiltonian dynamics on the symplectic extended phase space for autonomous and non-autonomous systems'', J. Phys. A: Math. Gen 38, 1257-1278, (2005)

\end{thebibliography}

\end{document}
