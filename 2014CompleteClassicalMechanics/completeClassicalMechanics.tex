\documentclass[aps,pra,10pt,twocolumn,floatfix,nofootinbib]{revtex4-1}

\usepackage{bbm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{amsfonts}
\usepackage{amsthm}

\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}

\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem*{assump1}{Classical assumption}
\newtheorem*{assump2}{Determinism and Reversibility assumption}
\newtheorem*{assump3}{Kinematic assumption}

\begin{document}

\title{From physical principles to relativistic classical Hamiltonian and Lagrangian particle mechanics}
\author{Gabriele Carcassi}
\affiliation{University of Michigan, Ann Arbor, MI 48109}
\email{carcassi@umich.edu}
\date{June 16, 2014}

\begin{abstract}
We introduce three fundamental principles (infinite reducibility, deterministic and reversible evolution, ) and show that classical mechanics can be derived them. The core idea is that deterministic and reversible systems preserve the number of labels we use to identify states, which puts considerable constraints and leads to the Hamiltonian and Lagrangian frameworks, space-time being locally Minkowskian, the general form of the Hamiltonian and equations of motion equivalent to those for relativistic charged particles. Many familiar fundamental concepts and constants (such as mass, the speed of light, the Plank constant, the vector potential) are introduced and defined in a novel way, thus providing different insight into them. The derivation strives to use definition and mathematical concepts that would allow a future extension to quantum mechanics.\end{abstract}
\maketitle

\section{Introduction}
Classical mechanics is usually founded on Newton's laws. These, though, are insufficient to derive the Lagrangian and Hamiltonian formalism, and usually other ad-hoc assumptions (e.g. conservative forces) are introduced. Special relativity is based on two principles (invariance of the speed of light and the principle of relativity), which lead to the Minkowskian nature of space-time but not to the equation of motion, which are a consistent reformulation of the non-relativistic ones. What we'll do in this work is see if we can re-organize all the known elements and equations in a more consistent and comprehensive way. The hope is that this gives us better insight on why the fundamental laws are what they are. Also, given that classical and quantum mechanics are formally equivalent, there is a chance that such work could be extended to quantum mechanics.

We'll first mathematically define states and the labels (e.g. position, momentum, temperature, pressure) we use to identify them. Using the principle of infinite reducibility (or classical assumption), the idea that each state is always divisible into the states of its sub-systems, we show that it is sufficient to describe the evolution of infinitesimal subsystem within their state space (or phase space).

Under the assumption of deterministic and reversible evolution, to each state corresponds one and only one future (or past) state, we show that the cardinality of labels (and states) is conserved. This allows us to define a metric on phase space, and the conservation of that metric leads to the Hamiltonian framework. That is: we can derive the Hamiltonian framework on its own merit and show that it is equivalent to deterministic and reversible motion.

We then introduce the principle of kinematic equivalence, the idea that studying trajectories is equivalent to studying states, and show that under this assumption we can define a transformation between state and kinematic variables. Noting that a passive coordinate change in space-time is equivalent to a re-labelling of states, and as such should conserve the phase space metric (i.e. the cardinality of states), the metric of space-time is constrained to be locally Minkowskian. Under the kinematic equivalence, the relationship between velocity and conjugate momentum has to be monotonic, leading to a concave Hamiltonian which allows a Legendre transformation leading to the Lagrangian. We can constrain the Hamiltonian further, and show that the most general form of motion under the three condition is the one of a geodesics modified by the force given by a vector potential, such as the one of a relativistic charged particle.

The above outline should help the reader maintain the big picture, as each section will go through the many details and definitions. We'll keep names and notation as consistent as possible to current use, but this may lead to some non sequitur as it will not be immediately clear why the different definition will be at the end equivalent to the standard one. This is still preferable than introducing a whole new set of names one has to become familiar.

While we try to keep a precise language, no mathematical breakthrough should be expected: the goal, after all, is to derive the \emph{known} framework from a set of \emph{simple} definitions in the most \emph{obvious} way possible. No proof is longer than a couple of paragraphs, so the word \emph{theorem} is avoided in favor of \emph{proposition} and \emph{corollary}. The novel, and surprising, result is how so much can be derived from so little.

\section{States, Labels and Maps}

The first two sections are dedicated to properly introduce states and the labels we use to identify them (such as position or temperature). The two issues that needs to be clarified are the nature of the system described (whole system vs infinitesimal component) and the cardinality of the states (discrete vs continuous variables). When talking about infinitesimal components and continuous labels, in fact, one must always remember that they are the result of a limit. Failure to do so would result in improper characterization of the system or counting of labels. We start with the whole system and discrete labels, then study the two limits separately.\footnote{Whole system vs infinitesimal component is also source of confusion when comparing classical and quantum states. Quantum states are always whole systems and are always distributions as there is no state uniquely attributed to its infinitesimal components.}

\begin{defn}\label{statedef}
Suppose we have a physical system to study. We define the set $\mathbbm{C}$ of all physically distinguishable configurations for that system. Each element $\mathbbm{c}$ we call \emph{configuration state}.
\end{defn}

\begin{assump1}\label{classical}
The system is infinitely reducible: it can be thought as composed by two or more similar but smaller systems, each in its own configuration state, which also can be thought as composed by two or more, ad infinitum.
\end{assump1}

\begin{defn}\label{classicalPhaseSpace}
Let $\mathbbm{S}$ be the set of all possible configuration states of the infinitesimal subdivision. We call this set \emph{phase space}. We call each element $\mathbbm{s}$ a \emph{state}.
\end{defn}

\begin{cor}\label{classicalDistribution}
Each classical configuration state $\mathbbm{c} \in \mathbbm{C}$ is a distribution over states: $\mathbbm{c}=\sum\limits_{\mathbbm{s} \in \mathbbm{S}} D(\mathbbm{s}) \mathbbm{s}$, where $D:\mathbbm{S}\rightarrow\mathbb{R}$ measures how much of the system can be found in each $\mathbbm{s}$. The distribution can be visualized as a histogram over the states in phase space.
\end{cor}

Under the classical assumption, we can then limit ourselves to the study of the infinitesimal elements, their states and their properties without loss of generality. To help identify states, we introduce the following concepts.

\begin{defn}\label{label}
We call a \emph{label} a set of states $i\subset\mathbbm{S}$; a \emph{set of labels} a collection of disjoint labels $I | \forall i_1,i_2\in I, i_1\bigcap i_2 = \emptyset$; a \emph{state variable} a set of labels $X$ that covers all of phase space: $\bigcup\limits_{i \in X}i=\mathbbm{S}$. Therefore a state belongs to one and only one label of a state variable.
\end{defn}

\begin{defn}\label{labelsCombine}
Let $I_1$ and $I_2$ be two sets of labels. We can define the \emph{combined set}, $\langle I_1, I_2 \rangle$, whose labels consist of all the non-empty intersections of one label of $I_1$ and one of $I_2$. If all intersections are non-empty, $I_1$ and $I_2$ are said to be \emph{independent}, and we have $n(\langle I_1, I_2 \rangle)=n(I_1)n(I_2)$ where $n: I \rightarrow \mathbbm{R}$ gives the number of labels of each set.
\end{defn}

We now want to study how states and labels evolve in time, under the following assumption.

\begin{assump2}
The system undergoes deterministic (future state identified by the present state) and reversible (past state identified by the present state) evolution.
\end{assump2}

\begin{prop}\label{detrevMap}
Let $\mathbbm{S}$ be the phase space of a system that undergoes deterministic and reversible evolution. There exists a bijective map $f:\mathbbm{S} \leftrightarrow \mathbbm{S}$ between past and future states.
\end{prop}

\begin{cor}\label{detrevDist}
The evolution of a classical configuration state $\mathbbm{c}=\sum D(\mathbbm{s}) \mathbbm{s}$ under a bijective map is given by $\mathbbm{c'}=\sum D'(\mathbbm{s}) \mathbbm{s}=\sum D(f^{-1}(s)) \mathbbm{s}$. The evolution of the fraction of the system in a label $D(i)=\sum\limits_{\mathbbm{S} \in i} D(\mathbbm{s})$ is given by $D'(i)=D(f^{-1}(i))$.
\end{cor}

Mathematically, assuming determinism and reversibility means studying bijective maps. The evolution of a distribution simply moves the elements around: the bars of the histogram move place, but keep the same height.

\begin{cor}\label{labelsCount}
Given a label $i$, the image $f(i)$ is also a label containing the same number of states. Given a set of labels $I$, the image $f(I)$ is also a set of labels containing the same number of labels. Given a state variable $X$, the image $f(X)$ is also a state variable. Given two independent sets of labels $I_1$ and $I_2$, the images $f(I_1)$ and $f(I_2)$ are also independent. Therefore $n(f(\langle I_1, I_2 \rangle))=n(f(I_1))n(f(I_2))=n(I_1)n(I_2)=n(\langle I_1, I_2 \rangle)$
\end{cor}

Bijective maps preserve the number of labels as they provide one-to-one association between future and past. And they do so for each independent set of labels. These simple results using discrete labels, properly generalized to the continuous case, will give us Hamiltonian flow.

\section{Continuous labels}

Numeric labels are prevalent in physics. For the discrete case, we can use integers and expect a one-to-one map between $z\in\mathbbm{Z}$ and $i\in I$. The deterministic map than becomes $f:\mathbbm{Z} \leftrightarrow \mathbbm{Z}$. For the continuous case, one may simply expect to replace $\mathbbm{Z}$ with $\mathbbm{R}$, but this presents a problem. In the continuous limit, the distribution of our infinitesimal states will become a density which is defined over infinitesimal intervals. Since the distribution and the states must be defined on the same object, the label is really an interval over $\mathbbm{R}$, not a point. This also makes physical sense, as we never deal with points per se, but widths that can be made arbitrarily small. With this in mind, we have the following definitions.

\begin{defn}\label{sdof}
A \emph{degree of freedom} is a state variable identified by an infinitesimal cell of $\mathbbm{R}$.
\end{defn}

\begin{defn}\label{sdof}
We define the \emph{generalized coordinate} $q$ as the center of each cell. We define the \emph{cell number}\footnote{This represents the classical analogue of the wave number.} $k$ such that $k \, dq$ represents the width of each cell.
\end{defn}

\begin{cor}\label{continuousLabels}
Each degree of freedom is identified by the pair of labels $\langle q,k \rangle$. As $k\,dq$ is invariant under coordinate changes, $dk\wedge dq$ is invariant and $k$ is contravariant.
\end{cor}

\begin{prop}\label{continuousLabels}
The cardinality of labels on a degree of freedom is given by $\omega = \hbar \, dq \wedge dk$, where $\hbar$ is a constant that defines the unit for labels.
\end{prop}

Since $q$ and $k$ are independent labels, the number of labels defined over a degree of freedom is the product of the labels defined on $q$ and $k$ (\ref{labelsCombine}). The number of labels for an interval of $q$ or $k$ will be proportional to said interval, therefore we have $\hbar \, dq \wedge dk$, where the constant is given by the choice of units for labels. It is customary to combine $\hbar$ with $k$.

\begin{defn}\label{sdof}
We define the \emph{conjugate momentum} $p=\hbar k$.
\end{defn}

\begin{cor}\label{continuousLabels}
Each degree of freedom is identified by the pair of labels $\langle q,p \rangle$. $\theta_0 = p dq$ and $\omega = dq \wedge dp$ are invariant, $p$ is contravariant.
\end{cor}

\begin{prop}\label{continuousLabelDist}
The configuration state over a degree of freedom is $\mathbbm{c}=\int D(q,p) \mathbbm{s}_{qp} = \int \rho(q,p) dq \wedge dp \mathbbm{s}_{qp}$, where $\rho(q,p)\equiv D(q,p) / \omega$ is the distribution density for each label.
\end{prop}

This is simply the limit of \ref{classicalDistribution} for the continuous case. Note that, since $\mathbbm{c}$ and $\omega$ are invariant under coordinate transformations, so is $\rho$.

In the language of differential geometry, we recognise the function $\rho$, the one-form $\theta_0$ and the two-form $\omega$. They are truly fundamental objects as they are intimately linked to the way states are defined ($\rho$ is the distribution, $\theta_0 / \hbar$ is the cell width) and counted ($\omega$ is the cardinality of the labels) and they don't depend on coordinate choice.


\section{Single degree of freedom}

We can now derive the equation of motions for the state variables under deterministic and reversible evolution.

\begin{defn}\label{canonical}
We define \emph{canonical transformation} a bijective map on one (or more) degree of freedoms.
\end{defn}

\begin{prop}\label{continuousMapping}
A canonical transformation must be continuous and preserve $\omega$.
\end{prop}

A bijective map conserves the cardinality of labels, see \ref{labelsCount}, therefore $\omega$ must be conserved. The map must be continuous in q, or it would split some cells into two parts: a cell would not be mapped to one and only one other cell, the mapping would not be bijective. The reverse mapping must be continuous in q as well, or the inverse would not map to one and only one cell.
\begin{align*}
dq' &= \frac{\partial q'}{\partial q} dq + \frac{\partial q'}{\partial p} dp \\
dq &= \frac{\partial q}{\partial q'} dq' + \frac{\partial q}{\partial p'} dp'
\end{align*}
We can re-express $dp'$ in terms of $dq$ and $dp$, as the conservation of $\omega$ means the map is non-degenerate, find that all partial derivatives are well defined, and therefore the mapping is continuous in p as well.

\begin{cor}\label{sdofInvariant}
Let $v$ and $w$ be two vectors defined on the tangent space of the manifold identified by two conjugate variables. Let
\begin{align*}
\omega_{a, b} = \left[
  \begin{array}{cc}
    0 & 1 \\
    -1 & 0 \\
  \end{array}
\right] \\
\end{align*}
then $v'^{a} \omega_{a, b} w'^{b}=v^{a} \omega_{a, b} w^{b}$ under a canonical transformation, where $a$ and $b$ represent component along coordinates $\xi^{a} \equiv \{q,p\}$.
\end{cor}

Here we are simply expressing $\omega$, $v$ and $w$ with their respective components and underlying the fact that $\omega$ defines the metric conserved under canonical transformations.

\begin{lem}\label{genAntisim}
Let $v$ and $w$ be two vectors. Let $v^{a} \omega_{a, b} w^{b}$ be an antisymmetric product conserved under a continuous transformation parameterized by $t$. We can then define a function $H$ such that given $S^{a} \equiv d_{t}\xi^{a}$ and $S_{b} \equiv S^{a} \omega_{a, b}$, we have $S_{a} = \partial_{a}H$.
\end{lem}

$S^{a}$ is the vector field that represents how the state variables change. Simply applying the vector transformation rules under continuous transformation we have:
\begin{align*}
v^{a} \omega_{a, b} w^{b} &= v'^{a} \omega_{a, c} w'^{b}  \\
&= (v^{a} + \partial_{c} S^{a} dt v^{c}) \omega_{a, b} ( w^{b} + \partial_{d} S^{b} w^{d} dt) \\
&= v^{a} \omega_{a, b} w^{b} + (\partial_{c} S^{a} v^{c} \omega_{a, b} w^{b} \\
 &+ v^{a} \omega_{a, b} \partial_{d} S^{b} w^{d}) dt + O(dt^2)
\end{align*}
\begin{align*}
v^{c} w^{b} \partial_{c} S_{b} - v^{a} w^{d} \partial_{d} S_{a} = 0
\end{align*}
\begin{align*}
\partial_{a} S_{b} - \partial_{b} S_{a} &= curl(S_{a}) = 0 \\
S_{a} &= \partial_{a}H
\end{align*}

\begin{prop}\label{sdofHam}
The time evolution for a single degree of freedom is given by:
\begin{align*}
d_{t}q &= \partial_{p} H \\
d_{t}p &= - \partial_{q} H
\end{align*}
\end{prop}

Simply expand \ref{genAntisim} with the metric defined in \ref{sdofInvariant}. We recognize Hamilton's equations for one degree of freedom\cite{classical_dynamics}.

\section{Multiple degrees of freedom}

\begin{prop}\label{mdofInvariant}
Let $v$ and $w$ be two vectors defined on the tangent space of the manifold identified by two independent degrees of freedom. Let $a$ and $b$ be indexes for the state variables $\xi^a\equiv \{q^i, p_i\}$. Let
\begin{align*}
\omega_{\alpha, \beta} =  \left[
  \begin{array}{cc}
    0 & 1 \\
    -1 & 0 \\
  \end{array}
\right] \otimes \left[
  \begin{array}{cc}
    1 & 0 \\
    0 & 1 \\
  \end{array}
\right] =
\left[
  \begin{array}{cccc}
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1 \\
    -1 & 0 & 0 & 0 \\
    0 & -1 & 0 & 0 \\
  \end{array}
\right] \\
\end{align*}
then $v'^{a} \omega_{a, b} w'^{b}=v^{a} \omega_{a, b} w^{a}$ under a canonical transformation.
\end{prop}

The independence between degrees of freedoms corresponds to orthogonality in phase space: from \ref{labelsCombine} the product between the number of labels on each d.o.f. (i.e. the area), must be equal to the number of combines labels (i.e. the hyper-volume), which is true only if the d.o.f are orthogonal in phase space. From \ref{labelsCount}, the mapping will preserve the cardinality of labels, the area\footnote{We assume we are using the same unit across d.o.f.} on each d.o.f, and the independence, orthogonality across d.o.f.\footnote{These statements provide a direct physical interpretation for Gromov's non-squeezing theorem\cite{Gromov,deGosson,Stewart}.} This is equivalent to requiring the conservation of the scalar product across independent degrees of freedom, while still requiring conservation of the vector product within. That leads us to the metric defined by \ref{mdofInvariant}.
The metric generalizes \ref{sdofInvariant} to give us the cardinality of labels defined on the area given by two arbitrary directions in phase space. For an infinitesimal region, this corresponds to $dq^1 \wedge dp^1 + dq^2 \wedge dp^2$, the sum of the projections on the independent planes. Moreover, volume in phase space corresponds to the cardinality of the combined labels (i.e. the states), and is therefore conserved: this is Liouville's theorem.

\begin{prop}\label{mdofHam}
The evolution for multiple degrees of freedom is given by:
\begin{align*}
d_{t}q^i &= \partial_{p_i} H \\
d_{t}p_i &= - \partial_{q^i} H
\end{align*}
\end{prop}

Expand \ref{genAntisim} with the metric defined in \ref{mdofInvariant}. We recognize Hamilton's equations for multiple degrees of freedom\cite{classical_dynamics}.

\section{Time dependence}

So far we have assumed that neither state labeling nor mapping change in time. If they do, we also need to to use time as a label and therefore introduce an extra degree of freedom.

\begin{defn}\label{tdof}
The \emph{temporal degree of freedom} is a state variable identified by temporal cells. The center of each cell is identified by $t$, the width by $\omega dt$, the conjugate variable $E\equiv\hbar\omega$. We call \emph{extended phase space} the outer product between phase space and the temporal degree of freedom.
\end{defn}

\begin{prop}\label{tdofMonotonic}
Let $s$ be the parameter of a trajectory in the extended phase space of a deterministic and reversible system. The trajectory must be continuous. There must exist a strictly monotonic function $t(s)$.
\end{prop}

The trajectory has to be continuous in both standard and temporal variables because of \ref{continuousMapping}. Since determinism and reversibility are defined in time, the trajectory must traverse all times once and only once: we must have an invertible mapping between $t$ and $s$, which means we must have a strictly monotonic $t(s)$.

\begin{defn}\label{tdofAntistates}
We call \emph{standard states} those connected by a trajectory where $d_{s}t>0$. We call \emph{anti-states} those connected by a trajectory where $d_{s}t<0$.
\end{defn}

Since $t(s)$ is strictly monotonic, $d_{s}t$ along a trajectory cannot change sign, so we have the division between standard and anti-states. Note that since the parametrization is conventional and can be changed to $s'=-s$, what we call standard and anti-states is also conventional. What is physical and not conventional, though, is that standard and anti-states cannot be connected by deterministic and reversible evolution.

\begin{prop}\label{tdofInvariant}
Let $v$ and $w$ be two vectors defined on the tangent space of the manifold identified by the temporal degree of freedom and one standard degree of freedom. Let $a$ and $b$ be indexes for the state variables $\xi^a\equiv\{t, E, q, p\}$. Let
\begin{align*}
\omega_{a, b} =  \left[
  \begin{array}{cc}
    0 & 1 \\
    -1 & 0 \\
  \end{array}
\right] \otimes \left[
  \begin{array}{cc}
    -1 & 0 \\
    0 & 1 \\
  \end{array}
\right]
= \left[
  \begin{array}{cccc}
    0 & 0 & -1 & 0 \\
    0 & 0 & 0 & 1 \\
    1 & 0 & 0 & 0 \\
    0 & -1 & 0 & 0 \\
  \end{array}
\right] \\
\end{align*}
then $v'^{a} \omega_{a, b} w'^{b}=v^{a} \omega_{a, b} w^{b}$ under deterministic and reversible evolution.
\end{prop}

$\langle t, E \rangle$ are not independent from $\langle q, p \rangle$ as they do not define new states. So they are not necessarily orthogonal in the extended phase space. Looking back at \ref{discreteLabelDef}, cells need to be defined on the plane where $\langle q, p \rangle$ (maximally) change: this is not the plane of constant $\langle t, E \rangle$ (they are not orthogonal) where $dq \wedge dp$ is defined, but the plane perpendicular to constant $\langle q, p \rangle$ where $dt \wedge dE$ is defined. On that plane we can properly count states and define our invariant.

We have a right triangle-like relationship between the plane where the invariant is defined and its projections on the planes defined by each d.o.f., similar to the multiple d.o.f.:
\begin{align*}
m.d.o.f \;\;\; &dq^1 \wedge dp_1 + dq^2 \wedge dp_2 = k \\
t.d.o.f \;\;\; &dt \wedge dE + k = dq \wedge dp \\
\end{align*}
But in the previous case, the right angle was between the two independent d.o.f.. In this case, the right angle is between the invariant and the plane of constant $\langle q, p \rangle$ where $dt \wedge dE$ is defined. We rewrite it as $dq \wedge dp - dt \wedge dE = k$. This corresponds to the Minkowski product across d.o.f. and the vector product within. The metric, with a space-like convention, still gives us the cardinality of labels within a degree of freedom.\footnote{Adjusted to avoid double counting.}

\begin{prop}\label{tdofHam}
The evolution for time varying multiple degrees of freedom is given by:
\begin{align*}
d_{s}t &= - \partial_{E} \mathcal{H} \\
d_{s}E &= \partial_{t} \mathcal{H} \\
d_{s}q^i &= \partial_{p_i} \mathcal{H} \\
d_{s}p_i &= - \partial_{q^i} \mathcal{H}
\end{align*}
\end{prop}

Take the metric from \ref{tdofInvariant}, add multiple independent d.o.f as in \ref{mdofInvariant}, use \ref{genAntisim} with the parameter $s$ instead of $t$ and generator $\mathcal{H}$ instead of $H$.

If we set\footnote{We avoided using $p^{n+1}$ as it hides the minus sign from the metric, making it seem that the temporal d.o.f is just another independent d.o.f.} $q^{n+1}=t$ and $p^{n+1}=-e$, we recognise Hamilton equations in the extended phase space\footnote{As in Struckmeier\cite{Struckmeier}, $d_{s}t$ need not be unitary.}\cite{Synge,Lanczos}.

It should not be a surprise that the equations do not mention the speed of light $c$. In fact, nothing says that all $q^i$ represent space or that the laws of motion are invariant in all inertial frames. The only requirement we have is that the areas of each degree of freedom represent the same cardinality for labels.

\begin{prop}\label{tdofConstrain}
The evolution is constrained by $\mathcal{H}=k$.
\end{prop}

Since $\mathcal{H}$ is constant through the evolution, it can serve both as the generating function and as the evolution constraint. By convention, we can set $\mathcal{H}=0$ without loss of generality as changing $\mathcal{H}$ by a constant does not change the equation of motion. This reduces extended phase space to $\mathbb{R}^{2*N + 1}$, the state variables plus time.

\section{Kinematics}
\begin{assump3}\label{kinematicAssumption}
The study of the motion of a body is equivalent to study its state under deterministic and reversible evolution.
\end{assump3}

\begin{cor}\label{}
Consider all states at $t=t_0$ and all possible trajectories, to each state corresponds one and only one trajectory; to each trajectory corresponds one and only one state.
\end{cor}

If studying the motion and state evolution are equivalent, given a state we must be able to reconstruct the trajectory, and given the trajectory we must be able to reconstruct the state. Given that the choice of state coordinates is arbitrary, we can use position and time as a set of continuous state variables: $q^\alpha = x^\alpha$. With that in mind:

\begin{prop}\label{}
A metric $g_{\alpha\beta}$ must be defined on the manifold identified by $x^\alpha$. All trajectories must be continuous.
\end{prop}

As each label corresponds to an infinitesimal cell, we need distances properly defined. This requires a metric defined on the manifold. And since evolution is continuous on state variables, it will be continuous in $x^\alpha$ as well.

\begin{defn}\label{continuousLabels}
An \emph{inertial frame} is one for which each direction of space represents a homogeneous state variable of an independent degree of freedom.\footnote{While a local inertial frame always exists, the existence of a global one is an added requirement. We add it because it makes the discussion easier and the proofs more obvious. Most of the results, though, will hold without that assumption. This will be important in future works that will try to extend this framework to general relativity.}
\end{defn}

\begin{cor}\label{continuousLabels}
The metric associated with an inertial frame is
\begin{align*}
g_{\alpha, \beta} =  \left[
  \begin{array}{cccc}
    -1 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1 \\
  \end{array}
\right] \\
\end{align*}
\end{cor}

The relationships between coordinates is the same as in phase space: $X^i$ must be orthogonal with each other, as the corresponding $Q^i$ are orthogonal in phase space; $X^i$ and $X^0$ are not in general orthogonal and it is the length perpendicular to time that gets conserved. Given that $X^\alpha$ are homogeneous, the metric must be invariant under translation, does not change in space-time, it is constant. With a suitable choice of units, we can set $|g_{\alpha\alpha}|=1$. All these combines gives us the Minkowski metric. We also introduce a constant $c$\footnote{Here $c$ is not defined as a a speed: it's the constant that allows to convert the cardinality of labels between space and time coordinates.} to convert time intervals to space intervals with the same number of labels, so we have $x^0=ct$.

It's important to note that the geometry of extended phase space and the geometry of space-time are linked: we cannot define cells in one without also defining cells in the other. This is true for all reference frames, not just inertial ones.

\begin{prop}\label{continuousLabels}
The position $x^\alpha$ and the velocity $dx^i/dt$ are necessary and sufficient initial conditions to determine the state of the system and its whole trajectory.
\end{prop}

The initial conditions will be given by the position and its first $n$ derivatives: $x^i_k=d^kx^i(t_0)/dt^k$ where $k=0..n$. This means that there is a function that, given the initial conditions, gives us the trajectory: $x(t)=f(t_0, x^i_k)$. We note that the initial conditions can be changed by an active transformation, therefore counting the number of possible initial conditions is equivalent to counting the possible number of active transformations. Under such change, though, the metric cannot change: it needs to be a change in initial conditions in the same reference frame, or we would double count each case. Defining the transformation for the position also defines how all its derivatives change, and by requiring the invariance of the metric, our options are actually very limited. Assuming we start from an inertial frame, only a linear transformation in all $x^\alpha$ can preserve the metric. A linear transformation can only change position and velocity, so the initial condition can only be limited to those. We also note that the active transformation can always change the velocity of $x(t)$, so $f$ must depend on the velocity or it would not be able to reach all possible trajectories defined by an active transformation in the same reference frame. Therefore position and velocity are both necessary and sufficient initial condition.

\begin{prop}
Principle of relativity. The laws of motion have the same form for all inertial observers.
\end{prop}

We saw that an active transformation that does not change the metric is a change in the initial conditions. Such a change should not affect the form of the function that given the initial conditions gives us the whole trajectory: the observer is the same, the law of motion is the same, they just shift the value of the arguments. But if the form of the laws of motion is preserved under such active transformations, it will also not change under passive transformation that preserve the metric. Given that all inertial observers can be reached by a linear transformation, which preserves the metric, then the laws of motion will have the same form.

%x(t)=f(x_0, x_1, ... x_n)

%What is the space size for a particular frame?

%We can reach any initial condition by coordinate changes
%But they also change f
%Free parameters are going to be the ones we can change without changing f
%How many coordinate changes are available to use without changing f?
%The ones that preserve the metric

%l_\alpha^\gamma l_\beta^\delta g_{\gamma\delta} = g_{\alpha\beta}

%Suppose different coordinate frame with same metric
%x'(t)=f(x'_0, x'_1, ... x'_n)


Assume trajectory are deterministic and reversible. Have state.

How much state? Find that is two per degree of freedom. Position and momentum are only state variables.

Inertial frame

\section{Connect to Hamiltonian}
\begin{prop}\label{continuousLabels}
Under the kinematic assumption, there must exist a bijective transformation $q^\alpha=q^\alpha(x^\alpha,u^\alpha)$ and $p^\alpha=p^\alpha(x^\alpha,u^\alpha)$ between initial conditions and state variables. As such, they are monotonic in both variables.
\end{prop}

As we have seen, $X^\alpha$ and $U^\alpha$ are state variables that fully identify our degrees of freedom. Nothing tells us, though, that
they are conjugate variables. But, since for every set of initial condition there must be one and only one state associated with it. This means the transformation must be invertible, monotonic.

\begin{prop}\label{continuousLabels}
Under the kinematic assumption, the extended phase space is defined on the conjugate variables $q^\alpha=x^\alpha$ and $p_\alpha=m\frac{dx_\alpha}{ds}+\hat{p}_\alpha(x)$.
\end{prop}

Given the degree of arbitrariness in choice of transformation, we can set $q^\alpha=x^\alpha$. This creates a direct link between how space is measured ($g_{\alpha\beta}(x^\alpha)$) and the width of our cells in phase space ($m(q)$)

$\partial_\alpha \delta^\beta_\gamma = 0 = \partial_\alpha g^{\beta\delta} g_{\delta\gamma} + g^{\beta\delta} \partial_\alpha g_{\delta\gamma}$

$\partial_\alpha g^{\beta\delta} g_{\delta\gamma} = - g^{\beta\delta} \partial_\alpha g_{\delta\gamma}$

$\partial_\alpha g^{\beta\delta} g_{\delta\gamma} g^{\gamma\epsilon} = - g^{\beta\delta} \partial_\alpha g_{\delta\gamma} g^{\gamma\epsilon}$

$\partial_\alpha g^{\beta\epsilon} = - g^{\beta\delta} g^{\gamma\epsilon} \partial_\alpha g_{\delta\gamma} $

$p_\alpha=m\frac{dx_\alpha}{ds}+\hat{p}_\alpha(x)$


$\frac{dx^\alpha}{ds}=\frac{\partial H}{\partial p_\alpha}=\frac{1}{m}(p^\alpha-\hat{p}^\alpha(x))$

$H=\frac{1}{2m}(p_\alpha-\hat{p}_\alpha)g^{\alpha\beta}(p_\beta-\hat{p}_\beta(x))+\hat{H}(x)$

$\frac{dp_\alpha}{ds}=-\frac{\partial H}{\partial q^\alpha}=$

$\frac{1}{2m}[\partial_\alpha \hat{p}_\beta g^{\beta \gamma} (p_\gamma -\hat{p}_\gamma)
 - (p_\beta -\hat{p}_\beta) \partial_\alpha g^{\beta \gamma} (p_\gamma -\hat{p}_\gamma)
 + (p_\beta -\hat{p}_\beta) g^{\beta \gamma} \partial_\alpha \hat{p}_\gamma ]- \partial_\alpha \hat{H}(x)=$

$\frac{1}{2}[\partial_\alpha \hat{p}_\beta u^\beta
- m u^\delta g_{\delta\beta} \partial_\alpha g^{\beta \gamma} u^\epsilon g_{\epsilon\gamma}
+ u^\gamma \partial_\alpha \hat{p}_\gamma ]- \partial_\alpha \hat{H}(x)=$

$\partial_\alpha \hat{p}_\beta u^\beta + \frac{m}{2}u^\beta \partial_\alpha g_{\beta \gamma} u^\gamma
- \partial_\alpha \hat{H}(x)=$

$m\frac{d^2x_\alpha}{ds^2}+\frac{d\hat{p}_\alpha(x)}{ds}$

$m\frac{d^2x_\alpha}{ds^2}=\frac{1}{2}[\frac{\partial\hat{p}_\beta(x)}{\partial x^\alpha} (\frac{dx^\beta}{ds}) + (\frac{dx_\beta}{ds})\frac{\partial\hat{p}^\beta(x)}{\partial x^\alpha} ]-\frac{\partial\hat{p}_\alpha(x)}{\partial x^\beta}\frac{dx^\beta}{ds}
-\frac{\partial \hat{H}(x)}{\partial x^\alpha}$

$m\frac{d^2x_\alpha}{ds^2}=(\frac{\partial\hat{p}_\beta(x)}{\partial x^\alpha} - \frac{\partial\hat{p}_\alpha(x)}{\partial x^\beta} ) \frac{dx\beta}{ds}
-\frac{\partial \hat{H}(x)}{\partial x^\alpha}$

Find that p must be contra-variant. Must be monotonic. And a linear transformation of v. Introduce mass. Introduce gauge.

\section{Lagrangian}

From Hamiltonian conservation to Lagrangian. p monotonic means convex Hamiltonian: can use Legendre transform.

\section{Conclusion}

\begin{thebibliography}{0}

\bibitem{Jaynes} Jaynes, E. T.: ``Information theory and statistical mechanics'', (1963)
\bibitem{Shannon} Shannon, C. E.: ``A mathematical theory of communications'', The Bell System Technical Journal, Vol. 27, pp. 379–423, 623–656, (1948)
\bibitem{classical_dynamics} J. V. Jose', E. J. Saletan: ``Classical Dynamics'', Cambridge University Press, (1998)
\bibitem{Gromov} Gromov, M. L.: ``Pseudo holomorphic curves in symplectic manifolds''. Inventiones Mathematicae 82: 307–347, (1985)
\bibitem{deGosson} de Gosson, M. A.: ``The symplectic camel and the uncertainty principle: the tip of an iceberg?'', Foundation of Physics 39, pp. 194–214, (2009)
\bibitem{Stewart} Stewart, I.: ``The symplectic camel'', Nature 329(6134), 17–18 (1987)
\bibitem{Lanczos} Lanczos, C.: ``The variational principles of mechanics'', University of Toronto Press (1949)
\bibitem{Synge} Synge, J. L.: Encyclopedia of Physics Vol 3/1, Springer (1960)
\bibitem{Struckmeier} Struckmeier, J.: ``Hamiltonian dynamics on the symplectic extended phase space for autonomous and non-autonomous systems'', J. Phys. A: Math. Gen 38, 1257-1278, (2005)

\end{thebibliography}

\end{document}
